# Prompting vs JSON Mode vs Function Calling vs Constrained Generation vs SAP
- URL: https://www.boundaryml.com/blog/schema-aligned-parsing
- Added At: 2025-06-29 12:06:14
- [Link To Text](2025-06-29-prompting-vs-json-mode-vs-function-calling-vs-constrained-generation-vs-sap_raw.md)

## TL;DR


本文介绍了从大型语言模型（LLM）提取结构化数据的九大技术，涵盖Prompt优化、模型约束及解析器方法，并提出新方案Schema-Aligned Parsing（SAP）。SAP通过错误纠正与模式驱动解析，在多模型测试中实现90%+准确率（如Claude-3达94.4%），显著优于传统JSON模式或函数调用方式。其优势包括自动修复语法逻辑错误、兼容复杂结构，并支持多语言开发。研究建议结合SAP与函数调用以进一步提升效能。

## Summary


本文探讨了从大型语言模型（LLM）提取结构化数据的多种技术，包括Prompting、JSON Mode、Function Calling、Constrained Generation等，并介绍了一种新方法Schema-Aligned Parsing（SAP）。以下是关键总结：

---

### **结构化生成的核心问题**
在给定查询（QUERY）和模式（SCHEMA）时，可通过以下三个维度影响输出结果生成：
1. **Prompt**：调整提示词的构建与模式呈现方式
2. **模型**：通过约束生成规则或函数调用改变模型输出
3. **解析器**：优化输出解析的策略与工具

---

### **九大技术分类**
| 类别       | 技术                     |
|------------|--------------------------|
| **Prompt** | 原始方法、提示工程、提示工程+解析   |
| **模型**   | JSON模式、约束生成、工具调用       |
| **解析器** | LLM重试、语言AST解析、SAP         |

---

### **技术对比（基于Berkeley函数调用基准测试）**
| **模型**             | 函数调用   | Python AST解析 | SAP      |
|----------------------|------------|----------------|----------|
| gpt-3.5-turbo        | 87.5%      | 75.8%          | **92%**  |
| gpt-4o               | 87.4%      | 82.1%          | **93%**  |
| claude-3-haiku       | 57.3%      | 82.6%          | **91.7%**|
| gpt-4o-mini          | 19.8%      | 51.8%          | **92.4%**|
| claude-3-5-sonnet    | 78.1%      | 93.8%          | **94.4%**|
| llama-3.17b（开源）  | -          | 60.9%          | **76.8%**|

---

### **技术分析**
#### **Prompt类**
- **原始方法**：直接提示生成JSON并解析 → **评分0/5**，LLM易出错。
- **提示工程**：优化提示词以减少JSON格式错误 → **评分0/5**，效果有限。
- **提示+解析**：条件解析（如仅在JSON有效时使用JSON.parse） → **评分0.5/5**，提升微弱。

#### **模型类**
- **JSON模式**：限制生成的token确保JSON合法性 → **评分2.5/5**，过于死板且不兼容复杂逻辑。
- **约束生成**：动态限制每一步生成的token → **评分2/5**，依赖自定义语法，维护困难。
- **函数调用**：模型触发JSON模式生成 → **评分3.5/5**，支持推理但仍有格式不准确风险。

#### **解析器类**
- **LLM重试**：多次请求直至成功解析 → **评分1/5**，成本高且效率低。
- **语言AST解析**：利用代码解析库（如Python AST） → **评分3.5/5**，依赖语法正确性，敏感易错。
- **SAP（推荐）**：基于模式的容错解析，修复LLM输出中的语法/逻辑错误 → **评分6/5**，最高准确率，兼容性最佳。

---

### **SAP核心优势**
1. **错误纠正**：自动修复JSON格式错误（如缺失引号、逗号、无效字符等）和逻辑错误（如数据类型不符）。
2. **模式驱动**：利用结构化Schema指导解析，而非依赖固定格式（如JSON）。
3. **性能提升**：对标现有技术，在多数模型中实现90%+准确率，开源模型表现提升显著（如llama-3.17b达76.8%）。

---

### **SAP实现**
- **跨语言支持**：Rust内核提供Python、TypeScript、Ruby等绑定。
- **工作流程**：
  1. 定义BAML schema（如定义数据类）。
  2. 在Prompt中声明输出格式。
  3. 通过命令行生成目标语言代码骨架。
- 示例代码片段可见于文档，支持自动类型验证与错误处理。

---

### **展望**
尽管LLM未来可能改进，但工程化优化（如SAP）仍能显著提升效率和成本效益。研究团队计划进一步结合函数调用与SAP以提升综合性能。
