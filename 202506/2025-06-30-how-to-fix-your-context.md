# How to Fix Your Context
- URL: https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html
- Added At: 2025-06-30 15:08:35
- [Link To Text](2025-06-30-how-to-fix-your-context_raw.md)

## TL;DR


该文提出优化语言模型上下文管理的六种策略：1.增强检索生成（精准添加参考信息）；2.工具组合（动态匹配最优工具集）；3.上下文隔离（拆分独立任务线程）；4.修剪冗余内容；5.压缩长上下文为摘要；6.将信息外置存储。核心强调主动管理上下文信息，平衡长上下文的优势与风险，通过结构化编程提升效率，根据任务需求选择优化方向。

## Summary


文章讨论了优化语言模型（LLM）上下文管理的六个战术，旨在解决上下文中毒、分心、混淆和冲突等问题。以下是核心要点：

### 一、**增强检索生成（RAG）**
- **定义**：选择性添加相关参考信息以提升响应质量。
- **案例**：Tiantian Gan和Qiyao Sun的“RAG MCP”方法通过向量化工具描述，精准选择工具，提升3倍准确性。
- **争议**：即使大模型（如Llama 4）拥有超长上下文窗口，滥用信息仍会引入噪声，“少即是多”原则仍适用。

---

### 二、**工具组合（Tool Loadout）**
- **理念**：效仿游戏装备组合逻辑，针对任务选择最佳工具集。
- **数据**：超过30个工具时模型易出现混淆；Llama 3.1 8b通过动态工具推荐性能提升44%，能耗和速度分别优化18%和77%。
- **实现**：结合LLM推理工具需求，通过语义搜索筛选工具。

---

### 三、**上下文隔离（Context Quarantine）**
- **策略**：将任务拆分为独立线程，每项任务拥有专属上下文。
- **案例**：Anthropic的多代理系统通过子代理并行探索，性能超越单一模型90.2%。
- **优势**：减少路径依赖，加速信息压缩，支持灵活工具配置。

---

### 四、**上下文修剪（Context Pruning）**
- **目标**：移除冗余信息，保留关键内容。
- **工具**：Provence在QA任务中能删除95%无关内容，仅保留相关段落。
- **建议**：维护结构化上下文（如字典格式），便于精准修剪并保留核心指令。

---

### 五、**上下文总结（Context Summarization）**
- **目的**：将长上下文精炼为摘要，防止模型过度依赖历史信息（如Gemini超10万token后易重复旧动作）。
- **实践**：作为独立压缩步骤，需明确需保留信息的标准，持续优化总结模型。

---

### 六、**上下文卸载（Context Offloading）**
- **方法**：将信息存储于外部工具（如“think”工具的思维笔记区），避免污染主上下文。
- **案例**：Anthropic的“think”工具提升专精代理基准测试表现54%，适用于复杂工具输出分析、政策合规验证和高风险决策。
- **挑战**：工具命名需直观（如“思维草稿本”更易理解）。

---

### **总结与启示**
- **核心原则**：上下文不是“免费”的，每个token影响模型行为。需主动管理信息，避免“垃圾输入，垃圾输出”。
- **优化方向**：通过结构化编程（如让模型自动生成提示）提升上下文效率，平衡长上下文的优势与潜在风险。
- **应用优先级**：根据任务需求选择策略，例如边缘计算场景侧重能耗与速度，复杂任务采用多代理或卸载工具。
