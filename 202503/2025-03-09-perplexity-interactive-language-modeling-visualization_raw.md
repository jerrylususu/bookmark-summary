Title: Perplexity: Interactive language modeling visualization

URL Source: https://perplexity.vercel.app/

Markdown Content:
I built this little tool to help me understand what it's like to be an autoregressive language model. For any given passage of text, it augments the original text with highlights and annotations that tell me how "surprising" each token is to the model, and which other tokens the model thought were most likely to occur in its place. Right now, the LM I'm using is the smallest version of GPT-2, with 124M parameters. For example, if I start counting to ten... one two three four five six seven eight nine ten .. you can see that the as the sequence progresses, the LM gets better at predicting the sequence and by the end it's 100% correct about how things are going to continue. One striking observation from this visualization is that LMs are particularly good at noticing and catching onto repetition. I'm not the first to discover this at all - Transformer language models tend to learn repeating patterns in language quickly in a mechanism called "induction". But it's very obvious in a visualization like this: The first time I write this sentence, the model is quite confused about what token is about to come next, especially if I throw in weird words like pumpkin, clown, tweets, alpha, teddy bear. But the second time? It expects almost every word that appears: The first time I write this sentence, the model is quite confused about what token is about to come next, especially if I throw in weird words like pumpkin, clown, tweets, alpha, teddy bear. This visualization runs entirely in your browser. No data is sent to any servers. Models running with transformers.js and frontend built with Oak (oaklang.org) :) More about induction circuits in transformers: https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html Inspired by: https://joel.tools/codegen/
