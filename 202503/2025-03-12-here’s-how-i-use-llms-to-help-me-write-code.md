# Here’s how I use LLMs to help me write code
- URL: https://simonwillison.net/2025/Mar/11/using-llms-for-code/
- Added At: 2025-03-12 14:37:07
- [Link To Text](2025-03-12-here’s-how-i-use-llms-to-help-me-write-code_raw.md)

## TL;DR
高效利用LLMs编程需明确其辅助角色，结合训练数据时效性选择可靠方案，通过多路径验证、精准指令及工具（如代码沙箱）优化开发。强调强制测试验证、人类主导关键决策，利用上下文迭代与反馈提升效率，同时警惕模型幻觉与安全风险。

## Summary
**文章总结：高效使用LLMs辅助编程的核心策略**

1. **合理预期**  
   - LLMs本质是高级语言模型，本质是预测标记的序列生成工具。不依赖其完美实现项目，而是作为“自信过载”的协作伙伴辅助开发，需结合人类判断测试修正。

2. **注意训练截止日期**  
   - 模型训练数据存在截止时间（如OpenAI模型截止2023年10月）。库更新、语法变化后需手动补充新版本示例，优先选择稳定库避免兼容问题。

3. **上下文是核心**  
   - 充分利用对话历史（prompt+回复）构建上下文。通过上传代码、提供示例、分阶段迭代开发。使用工具（如Claude的GitHub集成、Cursor）自动关联代码上下文。

4. **多方案对比**  
   - 初始阶段要求LM提供多项方案及示例（如“列出3种HTTP库并示例”），结合训练数据时效性选择可靠方案，快速验证可行性。

5. **精准指令控制**  
   - 设计好函数/模块接口后，用清晰的自然语言指令让LM实现细节。示例：指定函数签名及边界条件，LM生成函数体、测试用例，节省查文档时间。

6. **强制测试验证**  
   - 必须手动验证代码逻辑与结果。LM可能产生幻觉代码（如虚构API），测试是开发者的不可替代责任，尤其关注数据验证、异常处理等关键点。

7. **迭代对话优化**  
   - 对初稿不满意时，持续迭代指令（如“重构重复代码”“优化可读性”），LM可无抱怨多次修改。反馈循环能快速收敛到理想实现。

8. **运行环境工具**  
   - 优先使用带安全沙箱的交互工具（如Claude Artifacts、ChatGPT Code Interpreter），直接运行/调试代码。Cursor等集成开发环境可自动关联文件上下文。

9. **学习驱动的“vibe-coding”**  
   - 通过实验性开发快速试错，积累经验。作者以LLM为基础开发了77+工具原型，通过观察模型输出学习技术选型与实现模式。

10. **案例示范流程**  
    - 通过Colophon页面开发案例，展现从需求到部署的完整流程：逐步指令生成数据收集脚本→动态调整需求→自动化GitHub Actions配置→人工验证关键环节（如部署策略问题）。

11. **人类接管原则**  
    - 关键领域（如安全性设置）需人类主导。LLM擅长执行明确指令，但架构决策、潜在漏洞需结合人类经验判断。

12. **速度与扩展优势**  
    - 缩短开发周期，使原本因成本过高而放弃的小创意变为可能。持续使用加速技术吸收能力，如通过LM快速理解新工具（GitHub Actions配置语法）。

13. **技能放大效应**  
    - LLM的效用依赖用户现有经验。熟悉工具链和技术栈时，可高效引导LLM实施；陌生领域效果则大打折扣。

14. **代码问答辅助**  
    - LLM擅长根据代码注释或文档回答技术问题（如“解释这段Dockerfile的作用”），降低查阅资料时间成本。
