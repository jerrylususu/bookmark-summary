Title: Manus爆火的背后，Agentic AI产品如何构筑持久的竞争优势？

URL Source: https://yage.ai/manus.html

Markdown Content:
最近，Manus发布并迅速火遍了中文互联网。在深度使用了Manus以后，我觉得这个产品确实充满了启发。它抓住了Agentic AI产品竞争中非常重要的一方面，也就是复利效应。这篇文章就想聊一聊，对于类似Deep Research、Cursor或者Manus这样的Agentic AI产品，从更长时间的尺度来看，竞争的要点在哪些方面，以及哪些因素可以构成有效的护城河，哪些因素不可以。

在具体介绍Agentic AI产品竞争的三个重要方面之前，我想先解释一下为什么我觉得Manus是一个很惊艳的产品。其实，和很多自媒体渲染的情况不同，Manus不是一个石破天惊、从石头缝里蹦出来的产品，或者在它之前就没有任何人尝试过类似的产品形式。相反，它的出现是有着明确的发展脉络的。

和它最相关的两种产品形式，一个是Agentic调研类产品，比如Gemini、Perplexity和OpenAI的Deep Research。他们可以让你输入一个简单的主题或者要求，接着帮你调研全网的数据，并且生成一个详实且有深度的报告。另一种相关的形式是Cursor、Devin或者Gamma之类的Agentic生成类产品。你给它一个要求，它可以帮你写作代码、文稿或者幻灯片，直接交付你想要的产出形式。在2024年，这两种类型的产品都有了长足的发展，并且跨过了可用性的门坎，出现了病毒式的爆发增长。但是，还有一大痛点是：我要不然只能做调研，要不然只能写代码。二者之间并没有有效打通。

这其实是个非常微妙的痛点，因为Agentic AI好用的根本原因就在于，它通过自我迭代、自主决策，就可以帮我们一站式地完成复杂的任务。但如果我们在实际工作中还要不停地思考，这件事要用OpenAI的Deep Research来做，然后把结果复制粘贴到Cursor里面生成一些可视化的图像，最后再把这二者合并在一起，扔给Gamma去生成PPT，这其实完全和Agentic AI的初衷背道而驰，也丧失了使用Agentic AI的意义。

Manus让人觉得惊艳的地方就在于它打通了整条链路。一方面，它可以以Agentic的形式进行调研，通过浏览互联网来收集全面详实的资料。另一方面，它也可以根据这些资料，进行更多的分析、可视化，从而生成最终的产出，比如网站、图文报告或者幻灯片。这种端到端的应用场景在以往的产品中都是很难实现的。再加上，Manus本身产品特性打磨得也很好，完整度很高。作为一个思路精准又好用的产品，自然就引发了爆款。

工具的复利
-----

但是，上面的这些观察其实并没有触及到Agentic AI中更本质的特点，或者说优势。在我看来，Agentic AI相比于传统AI，一个鲜明的特征是它在多个维度上都具有复利效应（Compound Effect）。

在Manus的例子里，它为什么能取得成功，一个重要的原因是：它能使用的工具的数量比以往的产品都要多。这其实是一个并不trivial的区别。在Agentic AI产品中，能使用的工具的数量从6个到8个所带来的产品体验变化，要远远大于从2个到4个所带来的变化。这是因为AI所使用的工具之间是可以相互组合、相互促进的。如果一个AI只会写代码和搜索文本，这时候给它加一个图像搜索的功能，或许不会有太多的好处。但如果它在这个基础上还能写报告、做PPT，这个时候加入图像搜索的能力，就会一下让它产出的报告和幻灯片变得多彩很多，从而有力地推动了产品体验。而这恰恰是Manus干的事情。即使不论它做的其他创新，即使我们只看它把Deep Research和Cursor这两种产品并在一起，这个单纯的工具数量的增长，立刻就让它完成了很多以前的产品实现不了的场景。

这就是Agentic AI的第一种复利效应。当我们增加它能调用的工具的数量的时候，它带来的好处是组合的、爆炸式的增长。这是一种非常现实的增强用户体验的手段，但是它并不能构建一条有效的护城河。原因是在现在 Cursor 等等工具的支持下，单纯地对接某种工具让 AI 能够自主调用是一件非常简单的事情。如果抛开产品力不谈，只是想复刻一个 Manus 的话，这件事本身并不难。而单纯地通过卷工具的数量来构建护城河，也不是一个长久之计。

数据的复利
-----

而其实Agentic AI 在其他方面也有类似的复利效应。一个被很多人忽视的方面是数据。这里的数据指的不是类似LLM预训练的数据。你用了2T Token，我用了3T Token，我就比你厉害。在Agentic AI的时代，它有着更深刻的含义。确切地说，这里的数据指的不是数据量本身，而是横贯整个生命周期的数据的获取、组织和外化。在和人类共事的过程中，我们往往会体会到“家有一老，如有一宝”。比如工厂里一个机器坏了，老员工过来就知道在哪里拍一拍就可以把它弄好。或者有经验的医生看病的时候，随便摸两下就能把病因说得八九不离十。但是，刚毕业的小年轻往往要做很多检查项目才能约略得到类似的结论。

这就是一个典型的数据带来的好处。对于人而言，在这个过程中主要发生了两件事情：第一是经验的积累，无论是机械厂的员工还是医生，在他几十年的从业生涯中都遇到过很多类似的故障或者病例。在这个基础上，他就可以再进行第二步，总结归纳，也就是知识的组织。到了这一步，这些知识就被内化到他们的记忆里，对人类而言已经够用了。但是，由于AI与人类的沟通目前还完全依赖于书面沟通，所以往往还需要一个知识外化的过程，将它沉淀成一个明确的文档，才能被AI所使用。

因此，对于Agentic AI来说，维持一个知识积累、组织和外化的循环是非常重要的。一个我们之前提到过的软件工程的例子是，如果有一个写代码的AI，你直接给它一个十万行的代码仓库，并且给它布置一些任务，它一步成功就完成所有任务的概率其实不大。但如果你给它一些时间，让它逐渐阅读代码，并且加以理解、消化和分类，在这个基础上把它学到的东西总结、沉淀成一个个的文档，此时它的编码工作就会简单很多。

[这里](https://github.com/grapeot/web_agentic_ai/blob/master/claude-tooling/app/README.md)是一个这种文档的例子。在里面，我们介绍了代码的基本架构、设计思想、不同的函数放在哪些文件里。对于历史比较久的项目，我们还可以再加上一些历史的context。有了这些文档的支撑以后，一方面在空间上，AI就知道如何精准地定位要更改的代码，而不会无脑地去新建一个文件，把所有东西都从头写。从时间的维度上，AI也会知道之前做过哪些尝试，当前的设计思路是什么，而不会陷入鬼打墙，把设计方案又改回了以前的状态。因此，在这里我们所说的数据不是单纯的数据的堆砌、Token的叠加，而是一个长期的，自动或半自动化积累、理解和沉淀的过程。对于一个固定的客户来说，AI和他共事的时间越长，就可以积累越多的类似的知识。相比于另一个初来乍到、没有任何背景的AI，哪怕后者的智能程度更高，用户也会觉得前一个AI使用起来更舒服，它更懂我。因此这种知识系统的二次处理，是一个有效的护城河。

而类似的，这种数据的积累也有组合的复利效应。有更多的历史数据和总结出来的文档，AI就能通过对比和思考，形成更多的洞察。从某种程度上来说，这是一个把传统的知识系统变成一个AI友好（AI Friendly）的知识系统的过程。AI friendly不是一个非黑即白的二元状态，而是一个需要时间去沉淀和发展的东西。我甚至愿意把它和人与自然的共同进化（co-evolution）来类比。一方面，AI会从原始的知识库中进行挖掘、提炼和积累。另一方面，用户在使用AI的过程中也会越来越体会到，如果我们把各种数据让AI能轻松获取，对自己的工作而言也大有裨益。因此，他们就更愿意改变自己的工作方式来适应AI的数据管理流程。这又会带来额外的好处，比如以前在Zoom会议里面丧失的tribal knowledge，如果用户愿意引入Zoom AI Companion，那这些知识就会被捕捉下来，并且沉淀到文档库里，为AI所用来帮助用户。这就形成了一个双向奔赴的正向循环。而这个彼此的适应和默契，是一个非常强的护城河。

智能的复利
-----

Agentic AI还有一个非常有意思的特点，就是智能本身也是有复利的。这件事情可能不像工具和数据那么容易理解。但是，一个工具的智能程度会从多个角度对Agentic的用户体验带来影响。

最粗浅的角度是，越聪明的工具，它越知道怎么样去高效理解用户的需求，也知道怎么组合少数几个工具来获得最大的收益。比如，一个没那么智能的LLM，可能会东一榔头西一棒，调用了很多工具之后，还是没办法得到足够的信息。但是，会思考的LLM看起来就更有章法。通过巧妙地组合少数的几种工具，就可以在短时间内解决问题。

另一个相关的因素是，如果你对比过Gemini和OpenAI的Deep Research，就会发现这两个AI段位完全不一样。Gemini更像是机械地follow一个事先定好的指令，先想一些关键字上网搜索，然后自主决定抓取哪些网页，最后基于这些网页内容进行汇总回答。但OpenAI的Deep Research就会感觉更主动，自我迭代的能力也更强。它会先制定一个计划，然后根据计划用不同的关键字进行搜索。在搜索的过程中，根据结果它还可能动态调整策略。最终生成的答案往往也富有启发，不仅回答问题本身，还会自主延伸出下一步可能有价值的研究方向。这种自主性所带来的增益也是非线性的。

考虑到现在有能力进行自主LLM研发的公司并不多，同时，LLM的训练是一个非常强调资源和资本的事情。因此，这一定程度上也是一个有意义的护城河。

竞争的要点
-----

不过我想强调的一点是，这三种复利并不是平行的加法关系，而是有彼此激发和影响的乘数效应。工具数量的增多会为信息的处理和积累提供更多出口，比如在项目管理、搜索、文档生成等多个维度留下可以供 AI 学习的数据接口。AI 在分析这些信息的时候，也在不断提升自己的推理和理解能力。这种协同演化的效果在 Manus 中就非常明显。起初，Deep Research 能够做深入调研，Cursor 能够写代码、写文档，但一旦把二者融合在一个 Agentic 平台上，AI 就可以对调研得到的信息进行进一步的逻辑加工、编排和发布。而这些信息、工具和智能在同一个闭环中相互刺激，就给用户带来了一种更流畅、更智能的全流程体验。

因此，Agentic AI 竞争的重点可能就在于如何尽早地扩展到工具、数据或者智能这些指数增长曲线的右侧。这是因为花费同样的精力来增长工具的数量或者数据的数量，在初期得到的收益是相对有限的。但是，当它跨越一个 tipping point 以后，指数增长的威力就会显现出来。在曲线的右侧，每增加一个工具、增加一点数据，就会让用户的体验顺畅很多。因此，这可能是 Agentic AI 相关产品开展竞争、构建护城河的关键。当然，这条指数曲线并不一定会无限延伸下去，而可能是一个 S 形。到达某个节点以后，再继续加入新工具或者新信息，就会受到系统复杂度与资源投入的掣肘，导致增长减缓，甚至可能在某些阶段出现瓶颈。此时，可能就需要在架构和协作机制上做更深层的创新，来保持系统的协同演化。

而从上面的讨论也可以看出，在工具方面建立护城河不是特别可靠。从LLM智能方面建立护城河需要大量的资源，而从数据方面建立护城河可能是最简便可行的一种方法。在数据沉淀之外，可能更重要的是如何进行沉淀的流程与方法论。因为数据本身是可以复制的，但是如何系统性地将隐性知识外化，如何进行结构化沉淀以及高效数据管理，这是极其难以复制的。这类似于企业文化，一旦形成了强大的数据管理与知识外化的方法论和流程体系，即使竞争对手把这些数据和工具都复制过去，也很难在短期内复制这种隐性的组织能力。因此，在Agentic AI产品的长期竞争中，最难以攻破的不是数据或者智能的规模，而是这种数据与工具使用的体系化组织能力。

小结
--

从Manus出发，我们看到了Agentic AI领域竞争的关键点与护城河所在。但更重要的是，这场竞争并不仅仅是关于工具数量的比拼或数据规模的较量，而是组织如何适应AI时代的深刻转型。未来胜出的可能并不是拥有最强技术的公司，而是那些真正理解了AI与人类如何共进化、并能建立持续、稳定的协作机制的公司。这也许才是Agentic AI真正为我们带来的启示。
