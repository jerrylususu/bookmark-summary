# Giving your AI a Job Interview
- URL: https://www.oneusefulthing.org/p/giving-your-ai-a-job-interview
- Added At: 2025-11-12 14:32:47
- Tags: #read #llm
- [Link To Text](2025-11-12-giving-your-ai-a-job-interview_raw.md)

## TL;DR
基准测试易失真且忽略软技能评价，建议个人用户结合直观任务测试，企业用户需通过专家设计的场景化"AI面试"进行能力评估。

## Summary
当前评估AI智能的主要方式是使用基准测试（benchmarks），但其存在以下问题：基准可能被训练数据覆盖，导致分数虚高；测试内容与实际能力脱钩，如MMLU-Pro包含无关知识题；测试设计不完善，存在错误且分数难以校准。尽管如此，基准整体仍能反映AI能力的上升趋势，尤其在数学、科学和编程等领域。然而，基准在写作、商业分析等软技能上评估不足，导致用户无法针对性选择适合自身需求的AI。

为弥补基准的局限性，文章提出“氛围测试”（vibes-based benchmarking）作为补充方法，即通过定制化任务（如编写故事、生成代码）直观感受AI的响应质量、一致性和偏见。例如，不同AI对“无人机送鳄梨酱”创意的评分差异显著，反映出模型在风险判断上的倾向性。这种方法适合个人用户快速评估，但缺乏标准化。

对于企业用户，应采用更严谨的“AI面试”流程，参考OpenAI的GDPval研究：邀请行业专家设计真实任务，对比AI与人类表现，并由第三方盲测评估结果。这种方法能揭示AI在具体领域的强弱项（如GPT-5擅长销售管理，Claude长于财务顾问），并识别其决策倾向（如风险偏好）。企业需定期对AI进行场景化测试，而非依赖通用基准，以确保其适配实际业务需求。最终，选择AI应像招聘关键岗位一样，基于实际能力而非抽象分数。
