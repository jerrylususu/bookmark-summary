Title: 一次性软件与被压缩的现实：AI Native 的本质是策略重构

URL Source: https://grapeot.me/ai-native-cost-structure.html

Markdown Content:
一次性软件与决策解析度
-----------

一切从一个十分钟的需求开始。在机器学习研发工作中我们用Labelbox来让人类标注数据。有一次我发现标注的数据质量特别差，就打回去让他重标。第二天新的结果来了，我就想要快速看一下他到底做了哪些改动，有没有把错的改对。

在没有AI的传统工作流里，这是一个典型的低效环节。虽然我们有前后的 JSON 文件，但人类没办法直接解析和理解大规模的结构化数据。要搞清楚具体的改动，我只有两个选择。第一是自己写python代码做解析和比较，写前端HTML来做可视化。这至少需要一两个小时的编码和调试。但考虑到我只是想做一个十分钟级别的任务，投入两个小时的开发成本显然不划算。

因此绝大多数工程师会选择第二条路，人工抽样。我会用文本编辑器打开 JSON 文件，配合图片查看器，随机抽取十个样本进行人肉比对。这种方式很快，可以十分钟内搞定，但带来的决策质量也很低。它更依赖直觉甚至运气。我们看不到改动的全貌，只能基于极其有限的样本进行推断。这非常考验工程师的经验和水平，需要从蛛丝马迹中推断整体。

但是在AI时代，我用了第三种方法。我把前后版本的 JSON 文件和原始图片链接直接丢给 AI，让它做一个网站来可视化。两分钟以后，它生成了一个包含完整前后对比、过滤、排序和搜索功能的网站。通过这个工具，我不需要抽样猜测，不需要手工比对，不需要碰运气，而是直接查看了所有改动的分布，然后决定对某些场景的例子仔细检查。10分钟以后，我发现有些错误改对了，但还是有个特定场景错误很多。基于这个全量的检查，我做出了退回重标部分例子的决策。

这件事情让我不安的地方在于，那个功能强大的可视化网站，在我做完检查的那一刻就没用了。在传统的软件工程观念里，这是对开发资源的极大浪费。我们在整个学习和职业生涯中都被反复教导，要设计和编写可复用、可维护的代码，恪守DRY（Don’t Repeat Yourself）原则。这种用后即焚的一次性软件甚至是离经叛道的。

然而，正是这个一次性软件，将我从盲目抽样的低解析度决策中解放出来，让我拥有了对标注结果精细的、高解析的视野。换言之，当编写代码的成本接近于零时，以前离经叛道甚至匪夷所思的策略反而变成了最优策略：为了一个微小的临时需求，现场构建一个完善的专用工具。

隐形的价格表与被压缩的现实
-------------

回头想想，我们觉得理所应当的许多软件工程最佳实践，其实不是天生如此，而是特定经济环境或者说成本结构下的产物。

在数字世界中，系统的真实运行状态——无论是海量的日志、复杂的中间态，还是像 Labelbox 这样的结构化数据——对人类的感官都是封闭的。代码是构建产品的材料，更是我们观测数字世界的唯一有效途径。 我们必须编写代码去解析、过滤、可视化，才能将不可读的数据转化为可理解的信息。

但在旧有的成本结构里，代码是昂贵的资产，工程师的时间是稀缺资源。这意味着制造这个观测数字世界的工具的成本极高。因此，我们心里都有了一张隐形的价格表：为了查一个 Bug 专门写一套分析脚本是不划算的；为了让 PM 看懂逻辑专门开发一个后台界面是不划算的；为了验证一次数据质量专门搭建一个可视化网站更是天方夜谭。

由于构建观测工具的成本远高于问题本身的价值，我们负担起不获取高解析度观测的代价。 于是，我们被迫发展出一套妥协的生存策略：压缩现实。

我们提到的直觉、经验、以及各种所谓的最佳实践，很大程度上就是这种压缩策略的体现。比如Debug，在传统模式下，改代码打 Log 和分析 Log 都是高成本动作。工程师不可能为了Debug改100个地方来埋点打Log；而且就算打出来了几兆的Log，也读不下来。我们就只能在有限的几个地方打 Log 或者下断点，一个个试。仿佛对着一个黑盒猜测问题到底在哪里。

所以 Debug 一直被看作一门手艺，或者说一种艺术。这也异化了我们对技术专家的定义。我们职业成长的过程，本质上变成了一个训练自己在大脑中模拟机器运行的过程。 一个资深的工程师，应该拥有极强的“直觉”，能够依靠极其稀疏的线索，在脑海里构建出系统的运行模型，然后准确地猜出 Bug 的位置。我们花费数年时间去磨练这种盲猜的准确率，并引以为豪。但说到底，这是一种戴着镣铐跳舞的技能——我们是因为无法负担观测全貌的成本，才被迫把盲猜这门手艺练到了极致。

同样的逻辑也存在于团队协作中。对产品经理而言，工程系统看起来像一个黑盒。于是他们和工程师之间往往通过文档和工单沟通，而不是直接共享系统的实时运行状态。这是因为将代码逻辑转化为非技术人员能理解的可视化界面，开发成本太高了。于是，我们用契约和信任来替代透明的信息共享。

这也导致了产品经理职业能力的某种扭曲。一个资深的产品经理，往往被定义为能在这个黑盒外部极其精准地控制输入输出的人。 他们不需要理解系统内部发生了什么，而是学会了如何撰写滴水不漏的需求文档（更严苛的契约），或者如何通过人际关系建立信任来对抗交付的不确定性。他们的职业技能树，点满了“如何在看不见的情况下做决策”的技能点，而不是如何通过看见来做决策。

这种模式运行了很久，以至于我们已经习惯了，觉得这就是世界运行的唯一方式。我们认为直觉是高手的象征，认为抽样是标准的流程。但实际上，这只是因为我们处于一个信息获取成本高昂的时代，被迫接受了低解析度的现实。

而现在，AI 正在打破这张隐形的价格表。生成代码、分析数据、构建界面的成本呈数量级下降，我们不再需要对现实进行有损压缩。原本因为太贵而被舍弃的信息——那些海量的日志、全量的可视化对比、详尽的上下文——突然就几乎无成本地出现在我们面前。

这意味着，我们面临着一个非常具体的范式转移：从依赖直觉的低解析度决策，转向依赖全量数据的高解析度决策。那张旧有的价格表，实际上织成了一个无形的茧，将我们困在低解析度的世界里。在这个新时代，最危险的不是缺乏经验、没有直觉、猜不准，而是依然甘愿困在这个茧中，习惯性地忽略那些本可以被观测到的事实。

作为解压缩工具的一次性软件
-------------

在新的成本结构下，我们对软件代码的看法和最佳实践都要发生根本性的转变。长期以来，代码一直是被看作是需要精心维护的资产。因为昂贵，所以我们强调复用性，强调不要重复造轮子。但在 AI 时代，AI 对代码带来的最大变量，并不是帮我们更快地写完最终产品，而是将制造工具这件事的边际成本降到了几乎为零。

观测数字世界的工具变得如此廉价，让我们的行为模式发生了质变。试想一下，如果制造一台显微镜的成本比直接用肉眼费力观察还要低，那么理性的选择就是为每一粒灰尘都专门制造一台显微镜。

这就是我们在 Labelbox 案例中看到的模式：为了一次性的决策，构建一次性的软件。这种看似浪费的行为，实际上是针对特定问题最高效的解法。代码在这里不再是需要长期持有的资产，而变成了用完即焚的消耗品。

这种一次性软件本质上是廉价的解压缩工具。前面提到，现实世界的逻辑往往被折叠在黑盒里。因此，我们过去定义的职业成长，很大程度上是在训练一种在黑盒外盲猜的能力——我们积累经验、构建直觉，试图在看不见的情况下推断内部发生了什么。而一次性软件，则是将这些被折叠的黑盒——无论是代码逻辑、数据状态还是思维过程——暴力展开，平铺在人类面前。

这也意味着资深工程师的定义正在被改写。 以前，资深意味着拥有极强的模拟能力和技术直觉，能凭空推演复杂的逻辑，找到瓶颈；现在，资深意味着拥有极强的造工具的意识，能迅速构建观测体系来直接还原真相。

看看 Debug 是如何被这种逻辑重构的。在前 AI 时代，Debug 是一门依赖直觉的艺术。因为我们无法负担全量观测的成本，只能靠猜测来填补信息空白。但在新模式下，我们可以让 AI 瞬间编写出在数百个关键节点打点的代码，生成专门的日志分析脚本，甚至直接把 Log dump 到 2M 上下文窗口的 LLM 里去。我们不再需要像侦探一样从蛛丝马迹中推理，而是可以通过暴力搜索和全量数据分析，直接看到 Bug 的根源。Debug 从一种依靠运气的艺术，变成了一门依靠数据的科学。

这种解压缩同样适用于团队协作。以前，产品经理面对的是一个工程黑盒，只能通过文档和信任与工程师博弈。现在，我们可以为每一次需求沟通、每一个中间状态，快速生成一个临时的可视化界面。PM 不再需要看着晦涩的 Ticket 猜测进度，而是能直接看到系统的运行逻辑。这种一次性工具消除了翻译成本，让双方从基于契约的甲乙方，变成了基于透明事实的合作伙伴。

同样的逻辑也重塑了文档和知识管理。过去，我们只记录最高层级的战略结论，因为将大脑中流动的思维过程固化为文字的成本太高。现在，AI 允许我们将日常的讨论、中间的思考过程、甚至凌乱的草稿，低成本地转化为结构化的文档。

这里隐藏着一个巨大的复利效应。这些文档虽然是一次性生成的，甚至不需要被人阅读，但它们构成了极高解析度的个人知识库。当未来的我们、新入职的同事，甚至是未来的 AI Agent 需要回顾时，看到的不再是干瘪的结论，而是当时决策完整的背景和脉络。代码是用完即焚的，但通过代码沉淀下来的认知资产，会随着时间产生惊人的复利。

在这个阶段，廉价的代码不再是目的，而是手段。我们编写这些一次性代码，不是为了构建一座永恒的建筑，而是为了搭建一个临时的脚手架，让我们能爬上去看清楚黑盒里到底发生了什么。看清楚真相之后，这个脚手架就可以随手拆除，而毫无心理负担。

这种用代码换认知的模式，正是解开被压缩现实的钥匙。它开启了一种新的模式：不要吝啬算力，不要吝啬代码，因为在追求真相的高解析度视野面前，代码是最廉价的耗材。

AI Native 的本质是策略重构
------------------

当我们理解了信息获取成本的坍塌，以及一次性软件带来的解压缩能力，我们就能更准确地定义什么是 AI Native。

在目前的讨论中，人们往往把 AI Native 狭隘地理解为效率的提升。大家关注的是如何用 Copilot 更快地写出同样的函数，或者如何用 ChatGPT 更快地生成同样的文档。这仅仅是在旧有的路径上跑得更快，就像给马车换上了更快的马，但并没有改变马车的本质。

真正的 AI Native，是指在新的成本结构下，采用一种全新的最优策略。当行动的成本（写代码）接近于零时，最优的路径就不再是走直线（依赖直觉蒙混过关），而是把地图上所有可能的路径都探测一遍，再做决定。这种策略的转变，将沿着个人、团队和行业三个维度，重塑我们的工作方式。

在个人层面，这意味着决策直觉的根本转变。

一个真正的 AI Native 开发者，在面对不确定性时的第一反应，不再是调用自己的经验库去“猜”，而是思考如何现场构建一个工具去“看”。这种直觉的转变非常关键。以前，遇到一个棘手的 Bug，我们的本能是读源码、打断点、脑内模拟；现在，本能应该是写个脚本分析一下日志或者让 AI 写个可视化插件把内部状态画出来。

这种转变要求我们克服节约代码的旧习性。我们必须习惯于为了一个十分钟的决策，挥霍算力去构建一个五分钟后就报废的工具。因为在新的经济模型里，代码是廉价的耗材，而决策的准确性是昂贵的资产。用廉价的代码去换取昂贵的认知确定性，是新时代最基本的套利行为。

在中观层面，这意味着组织信任机制的重构。

传统的软件组织架构，很大程度上是为了应对黑盒而设计的。产品经理与工程师之间、甲方与乙方之间，本质上是一种基于契约的对抗关系。因为看不见内部细节，所以必须通过详细的文档、严格的工单和繁琐的流程来控制风险。信任是稀缺的，往往建立在人际关系或过往的履历上。

但在 AI Native 的模式下，一次性软件赋予了我们激进透明（Aggressive Transparency）的能力。我们可以为每一个中间环节、每一次需求变更，快速生成可视化的界面或数据看板。当黑盒被打破，当利益相关者能直接看到系统的实时运行逻辑时，基于猜测和防御的对抗关系，自然会转化为基于事实和共识的协作关系。

信任不再需要通过人际关系去小心维护，也不再需要通过僵化的流程去强制保障，而是建立在高度透明的信息基础之上。这种零阻力的协作模式，将彻底改变软件团队的组织形态。

在宏观层面，这意味着交付物的重新定义。

随着用户生成软件（User Generated Software）能力的提升，软件公司交付的价值也在发生变化。过去，我们交付的类似功能固定的成品家具，用户只能在预设的范围内使用。这是因为让用户自己修改代码的成本太高。

但在未来，我们更多交付的将是一种[生成内核（Generative Kernel）](https://grapeot.me/ai-software-engineering.html)。我们将核心的业务逻辑、数据结构和最佳实践封装起来，作为地基。在这个地基之上，AI 可以根据用户具体的、临时的、甚至是一次性的需求，随时生成各种形态的接口和工具。

这是一种复利的终极形态。我们不再试图穷尽所有用户需求去开发功能（这是旧成本结构下的做法），而是致力于降低用户构建专用工具的门槛。无论是通过文档沉淀下来的知识，还是通过 API 暴露出来的能力，最终都服务于同一个目标：让每个人都能以极低的成本，通过 AI 构建出属于自己的高解析度视图。

结语
--

撕碎那张隐形的价格表，突破那只无形的茧，羽化成蝶，需要的不是Cursor，Claude，GPT，而是认知的刷新。

在这个新时代，最大的风险不再是由于技术限制而看不见，而是为了坚持旧有的软件工程教条，而刻意选择不去看。当获取真相的成本已经低如尘埃，拥抱高解析度的现实，才是 AI Native 赋予我们真正的杠杆。