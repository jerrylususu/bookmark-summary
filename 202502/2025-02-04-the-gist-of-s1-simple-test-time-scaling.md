# The gist of s1: simple test time scaling
- URL: https://xeiaso.net/notes/2025/s1-simple-test-time-scaling/
- Added At: 2025-02-04 08:14:17
- [Link To Text](2025-02-04-the-gist-of-s1-simple-test-time-scaling_raw.md)

## TL;DR
文章讨论了通过提示AI模型继续思考来提高其回答准确性的方法，特别适用于复杂问题。该方法在数学竞赛问题上显著提高了模型性能，作者认为这种方法简单有效，并计划在未来研究中应用。

## Summary
1. **文章概述**：
   - 文章发布于2025年2月3日，全文1350字，阅读时间约5分钟。
   - 简述：当模型认为它已经完成思考时，告诉它再思考一会儿，这种方法简单且有效。

2. **问题背景**：
   - 文章讨论了两种类型的AI模型：一种是快速响应的模型，另一种是经过深思熟虑后才回应的模型。
   - 后者（深思熟虑的模型）通常更准确，尤其适合处理复杂的数学问题，但有时会过早停止推理。

3. **模型输出示例**：
   - 文章通过一个简单的问题“raspberry中有多少个字母'r'？”展示了模型的推理过程。
   - 模型通过逐步分解问题，确认每个字母，最终得出正确答案：3个'r'。

4. **内部机制**：
   - 模型在推理过程中会生成类似“<think>”和“</think>”的标记，表示模型在“思考”。
   - 这种方法帮助模型将复杂问题分解为更简单的部分，从而得到更准确的答案。

5. **研究提出的改进方法**：
   - 配置模型以将“</think>”标记视为“停止标记”，表示模型停止推理。
   - 移除“</think>”标记，并在输出末尾添加“Wait”和新行，重新运行模型。
   - 重复上述步骤几次，称为“推理努力”，以进一步修正答案。
   - 这种方法在MATH500和AIME24等竞赛级数学问题集上显著提高了模型的得分。

6. **作者观点**：
   - 作者认为这种方法非常有效，因为它允许用户调整“推理努力”参数，从而在延迟和准确性之间进行权衡。
   - 作者推测存在一个“平衡点”，过多的推理努力可能不会进一步改善结果。

7. **应用场景**：
   - 这种方法可以用于在没有自定义语法支持的运行时中，使推理模型支持结构化输出。
   - 作者通过Ollama结构化输出API进行了测试，成功让模型输出更详细的加拿大相关信息。

8. **作者的实验结果**：
   - 作者的实现生成了包含加拿大国家名称、ISO代码、首都、语言和历史事件的结构化输出。
   - 作者计划将这种方法用于未来的研究项目。

9. **技术限制**：
   - 作者提到希望拥有更多高性能GPU以加快迭代速度，但由于某些型号的GPU存在高故障率，作者选择暂时不购买。

10. **版权声明**：
    - 文章版权属于Xe Iaso，所有观点仅代表作者本人，不代表任何雇主。
