# Can LLMs write better code if you keep asking them to “write better code”?
- URL: https://minimaxir.com/2025/01/write-better-code/
- Added At: 2025-01-03 15:34:47
- [Link To Text](2025-01-03-can-llms-write-better-code-if-you-keep-asking-them-to-“write-better-code”_raw.md)

## TL;DR
2023年11月，OpenAI在ChatGPT中集成了DALL-E 3的图像生成功能，展示了LLM在生成内容时的迭代能力。随后，实验探讨了通过不断要求LLM“write better code”来改进代码质量的可能性。实验使用Claude 3.5 Sonnet生成Python代码，并通过多次迭代优化代码性能，最终提升100倍。实验表明，提示工程可以显著加速代码优化，但仍需人工干预以确保代码的正确性和效率。所有代码和实验数据可在GitHub上获取。

## Summary
1. **背景介绍**：
   - 2023年11月，OpenAI在ChatGPT中集成了DALL-E 3的图像生成功能，用户可以通过不断要求模型“make it more X”来生成更符合要求的图像。
   - 这种趋势虽然短暂，但展示了LLM在生成内容时的迭代能力。

2. **实验动机**：
   - 探讨是否可以通过类似的方式，通过不断要求LLM“write better code”来改进代码质量。
   - 代码质量可以通过客观标准衡量，不像图像生成那样主观。

3. **实验设计**：
   - 使用Claude 3.5 Sonnet进行实验，因其在代码生成方面的出色表现。
   - 实验任务：编写Python代码，从100万个1到100,000的随机整数中，找到数字之和为30的最小和最大数，并计算它们的差值。

4. **初始代码实现**：
   - 初始代码实现了一个简单的算法，遍历列表并计算数字之和，性能基准为657毫秒。
   - 代码虽然正确，但存在优化空间，如避免类型转换等。

5. **迭代优化过程**：
   - **第一次迭代**：代码被重构为面向对象的形式，并预计算数字之和，性能提升2.7倍。
   - **第二次迭代**：引入并行处理和向量化操作，性能提升5.1倍。
   - **第三次迭代**：代码变得更加复杂，但性能略有下降，仅提升4.1倍。
   - **第四次迭代**：引入numba库和异步处理，性能提升100倍，但代码变得过于复杂。

6. **提示工程优化**：
   - 通过更明确的提示工程，要求代码必须完全优化，Claude生成了更简洁且性能更好的代码。
   - **初始提示工程**：代码性能提升59倍。
   - **第一次迭代**：引入并行处理和位操作，但性能下降至9.1倍。
   - **第二次迭代**：引入SIMD操作和预计算哈希表，性能提升65倍。
   - **第三次迭代**：优化哈希表生成逻辑，性能提升100倍。
   - **第四次迭代**：修复数字之和计算错误，性能提升95倍。

7. **实验结果总结**：
   - 通过不断要求LLM“write better code”，代码确实得到了改进，但改进的方向和程度取决于提示的明确性。
   - 提示工程可以显著加速代码优化过程，但也更容易引入细微的错误。
   - 最终，LLM生成的代码需要人工干预来修复不可避免的问题。

8. **未来优化方向**：
   - LLM未尝试去重或排序等统计优化方法，这些方法可能进一步提升性能。
   - 尽管LLM在代码生成方面表现出色，但仍需人工干预以确保代码的正确性和效率。

9. **代码和实验数据**：
   - 所有代码和实验数据可在GitHub上获取，供进一步研究和验证。
