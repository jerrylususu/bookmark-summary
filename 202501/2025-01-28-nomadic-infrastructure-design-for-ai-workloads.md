# Nomadic Infrastructure Design for AI workloads
- URL: https://xeiaso.net/talks/2025/nomadic-compute/
- Added At: 2025-01-28 03:47:28
- [Link To Text](2025-01-28-nomadic-infrastructure-design-for-ai-workloads_raw.md)

## TL;DR
演讲者Xe分享了如何设计高效、低成本的生产级AI系统，重点讨论了计算、网络和存储的优化策略，如缩放到零、批量操作和加速冷启动。通过Docker镜像优化和游牧计算，系统可跨平台运行，减少对特定供应商的依赖。演讲还展示了按需启动GPU的现场演示，并提供了联系方式供观众提问。

## Summary
1. **演讲主题**：演讲者Xe讨论了如何设计一个生产级的AI系统，以最大化每美元的效益，并减少对特定供应商的依赖。

2. **工作负载的三个基本部分**：
   - **计算**：负责数字运算或线性代数。
   - **网络**：连接所有计算机。
   - **存储**：保存数据以供下次使用。

3. **计算与存储成本的对比**：
   - **计算时间比存储时间便宜**：通过Vast.ai和RunPod等平台，下载数据的成本低于存储数据的成本。
   - **实例成本分析**：以4090显卡为例，运行成本为每小时2美分，而存储成本为每小时1美分。

4. **基础设施设计的“作弊”方法**：
   - **缩放到零**：在用户不使用服务时关闭服务，每天可节省12小时的运行时间。
   - **批量操作**：将工作负载集中在特定时间段内执行，如每日一次的壁纸生成应用。
   - **加速冷启动**：通过将模型权重嵌入Docker镜像中，减少冷启动时间。

5. **Docker镜像的优化**：
   - **模型权重不变**：将模型权重嵌入Docker镜像中，减少运行时下载时间。
   - **Docker的限制**：Docker Hub对镜像大小有限制，需使用自定义注册表。

6. **游牧计算的核心思想**：
   - **自包含的工作负载**：工作负载包含所有所需资源，能够快速启动并完成任务。
   - **不受限于云供应商**：只要支持AMD 64字节码和Nvidia GPU，工作负载可以在任何平台上运行。

7. **现场演示**：
   - **HTML 1.0表单**：通过点击按钮生成动漫女性图像，GPU按需启动并在完成后关闭。

8. **总结与感谢**：
   - **特别感谢**：演讲者感谢了所有支持此次演讲的人。
   - **联系方式**：演讲者提供了联系方式，欢迎观众提问。

9. **版权声明**：
   - **版权归属**：所有观点均为演讲者个人观点，不代表任何雇主。
   - **网站信息**：演讲内容由xesite v4提供，源代码可在GitHub上获取。
