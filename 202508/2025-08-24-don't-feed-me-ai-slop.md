# Don't feed me AI slop
- URL: https://www.seangoedecke.com/dont-feed-me-slop/
- Added At: 2025-08-24 04:23:32
- [Link To Text](2025-08-24-don't-feed-me-ai-slop_raw.md)

## TL;DR


文章提出AI内容展示的核心标准是"内容密度"，即信息量和精准度需达到人工水平。低质AI内容即使标注也会引发反感，规范应重质量而非形式。例外情况包括翻译和客观数据展示，代码生成需深度审核以避免缺陷。最终强调AI协作需主动筛选重构，确保信息高效传递。

## Summary


文章探讨了AI生成内容在社交互动中的使用规范，提出"内容密度"是判断是否应展示AI内容的核心标准。当AI生成内容具备与人工创作相当的信息密度时，其展示是可接受的；反之则引发不适感。

主要结论：
1. **核心原则**：展示AI内容应满足"内容密度"标准，即其信息量、精准度与人工创作相当。冗长空洞、模糊通用的输出（slop）会引发反感。

2. **披露规范的局限性**：
   - 即使明确标注AI生成，低质内容仍令人不适（如Quora机器回答、格式化邮件）。
   - 强制披露未能解决根本问题，需补充质量评估标准。

3. **例外情况**：
   - **翻译**：AI辅助语言转换不违背社交规范，因其传递核心内容而非创造新表达。
   - **技术事实**：简洁列举客观数据（如历史事故列表）可接受，但长篇论述需人工把控。

4. **代码生成的特殊要求**：
   - 优质AI代码需避免三个缺陷：冗余代码（如多余注释/异常处理）、违背代码规范、逻辑错误（如不切实际的设计）。
   - 使用AI生成代码需深度审核，如同人工编码——审查效率提升是其核心价值而非替代思考。

5. **个人体验差异**：
   - 作者对自身AI交互无异议，但反感他人AI输出的"次生内容"，认为这涉及人际信任感。
   - 案例显示，人类更易接受经精心筛选的AI内容而非直接输出。

文章强调，AI使用的社会规范应聚焦质量而非形式，内容密度是判断AI协作合理性的关键，这要求使用者主动过滤、重构AI输出以保持信息高效性。
