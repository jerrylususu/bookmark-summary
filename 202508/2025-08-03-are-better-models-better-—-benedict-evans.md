# Are better models better? — Benedict Evans
- URL: https://www.ben-evans.com/benedictevans/2025/1/the-problem-with-better-models
- Added At: 2025-08-03 15:25:49
- [Link To Text](2025-08-03-are-better-models-better-—-benedict-evans_raw.md)

## TL;DR


文章指出，更复杂的AI模型未必实用，因其本质是概率系统，虽在容错高的领域（如营销）有效，但在医疗、法律等需精准判断的任务中易出错且无法自检。作者建议重新定义AI价值，接受其不完美以探索新场景，而非追求替代传统工具的绝对正确性，类似于技术革新常通过开创而非取代旧范式实现突破。

## Summary


文章探讨了“更优秀的AI模型是否真的更好”的问题，指出当前生成式AI在任务上的局限性。尽管每周都有新模型发布，但许多问题并不存在“更好”答案，仅存在“正确”或“错误”之分。例如，作者测试多个版本的Midjourney生成图像，新版本虽“更好”，但主观质量提升未必实质改变用户体验。通过具体案例——询问1980年美国电梯操作员人数，展示AI模型在需要精确数据的任务中反复出错，且无法自检错误，导致用户难以信任结果。这是因为生成式AI本质是概率系统而非确定性工具，擅长生成“可能正确”的答案，而非确保“绝对正确”。

文章指出，生成式AI在软件开发、营销领域成功，因其任务容错性高且无绝对答案，用户可快速修正误差。然而，涉及法律、医疗等专业领域，模型的“错误”风险显著，尤其当用户缺乏专业知识时，可能完全无法依赖。当前缓解方案包括将AI嵌入传统软件系统，通过工具控制误差率，或如Claude般主动回避风险问题。但根本问题仍未解决：AI模型是否能通过扩展或理论突破实现“理解”并输出确定性答案？作者认为，技术发展可能遵循历史模式：早期技术常被用于改良旧问题（如用AI优化传统流程），但其真正价值可能在于开辟新场景（如颠覆性应用），而非替代现有解决方案。以苹果从硬盘随身听转向Flash内存，再转向智能手机为例，技术接受度随用户对新范式的适应而变化。生成式AI或许同样需重新定义用户预期，接受其不完美以获取新型价值，而非强求其满足传统计算机的“绝对正确”标准。
