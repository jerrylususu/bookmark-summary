# Is chain-of-thought AI reasoning a mirage?
- URL: https://www.seangoedecke.com/real-reasoning/
- Added At: 2025-08-13 14:09:50
- [Link To Text](2025-08-13-is-chain-of-thought-ai-reasoning-a-mirage_raw.md)

## TL;DR


亚利桑那州立大学论文认为大型语言模型（LLMs）的链式推理是“海市蜃楼”，基于小模型在简单字母变换任务的变体中表现不佳，认为其推理仅复制训练数据。作者反驳称该实验任务设计简单，未体现人类动态思考；模型规模过小，无法反映大模型涌现的复杂推理能力；且人类推理本身依赖模板且易受格式干扰。最终指出，讨论AI推理的本质需明确哲学定义，避免过度泛化结论，需通过多路径任务设计严谨验证。

## Summary


文章讨论了亚利桑那州立大学（ASU）关于大型语言模型（LLMs）的链式推理是否为“海市蜃楼”的论文。该论文通过训练小规模模型（约60万参数）处理字母变换任务，发现在分布外或任务格式略微变化时，模型推理性能显著下降，认为其链式推理仅是复制训练数据中的模式，而非真实推理。作者认为这一结论存在局限：

1. **任务设计问题**：实验中的字母变换属简单计算而非真正推理，缺乏人类推理中常见的思考路径调整（如“Wait”等指示词），无法反映复杂推理过程。  
2. **模型规模不足**：小型模型缺乏支持复杂推理的“脑力”，而真正推理是大模型的涌现能力（如百亿参数模型），论文结论无法推广至大模型。  
3. **忽视人类推理特性**：人类推理同样依赖模板、易受格式干扰且超出领域表现不佳，论文未考虑人类实际推理模式，错误假设“理想推理者”作为标杆。

作者指出，讨论AI推理是否“真实”需明确推理的哲学定义，而现有研究常过度泛化结论。好的研究应避免主观判断，专注于设计需多路径解决的任务，并评估人类基准。最终强调：推理本质是哲学问题，需严谨论证而非简单归结为“幻象”。
