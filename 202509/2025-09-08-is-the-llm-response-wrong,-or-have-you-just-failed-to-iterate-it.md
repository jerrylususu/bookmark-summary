# Is the LLM response wrong, or have you just failed to iterate it?
- URL: https://mikecaulfield.substack.com/p/is-the-llm-response-wrong-or-have
- Added At: 2025-09-08 14:27:56
- [Link To Text](2025-09-08-is-the-llm-response-wrong,-or-have-you-just-failed-to-iterate-it_raw.md)

## TL;DR
文章讨论了一张二战飞行员照片的误判案例，说明LLM的初步回应常因信息混杂而错误，但通过迭代查询（如排序提示）可以提升准确率。建议用户主动推动多轮查询来验证事实，而非直接接受初始答案。

## Summary
1. **问题背景**  
   - 文章讨论一张常被误认为是二战飞行员Shirley Slade的照片，但实际是模特Casey Drabble在2016年的拍摄照片。
   - Google AI Mode对此图像的回应有时正确，有时错误，错误时会误判为Shirley Slade。

2. **LLM的回应分析**  
   - LLM的初始回应并非“幻觉”（完全凭空捏造），而是基于现有信息（如社交媒体帖子）的混淆、不完整发现或证据权重分配不当。
   - 这种行为类似于人类在混乱信息环境中的初步反应：收集现有观点，但未深入验证。

3. **迭代的重要性**  
   - 通过后续提示（如“证据支持和反对此照片是Shirley Slade的理由”），LLM能进行第二次搜索和推理，最终得出正确结论。
   - 这模仿了人类事实核查的过程：先提出初步理论，再通过迭代搜索和证据对比逐步接近真相。

4. **批评与误解**  
   - 人们常将LLM的错误回应归咎于其不可靠，但作者指出这实际上是未能进行迭代查询的结果。
   - 传统事实核查同样依赖多次搜索和证据评估，LLM的行为本质上是“进行中”的初步结果，而非最终结论。

5. **实用建议：排序提示**  
   - 作者提出使用“排序提示”来引导LLM迭代，例如：
     - 要求列出证据支持和反对某一观点。
     - 区分社交媒体传闻与可靠来源（如报道、学术研究）。
     - 追踪信息来源或最新动态。
   - 这些提示能减少用户偏见，提高回应的准确性和深度。

6. **结论**  
   - LLM的初始回应应被视为信息环境的快速扫描，而非最终答案。
   - 用户应主动推动迭代查询，尤其在重要问题上，以挖掘更准确的信息。
   - 平台应设计功能鼓励用户迭代查询，而非直接争论结果。

7. **附加说明**  
   - 作者强调，大多数用户高估自身信息检索能力，实际需要训练才能有效核查事实。
   - 迭代方法能显著提升LLM回应的可靠性，但需避免过度依赖单次查询。
