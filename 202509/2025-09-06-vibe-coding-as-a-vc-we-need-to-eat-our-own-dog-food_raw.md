Title: Vibe-Coding as a VC: We Need to Eat Our Own Dog Food

URL Source: https://kevinkuipers.substack.com/p/vc-for-vibe-coding-a-fresh-new-start

Published Time: 2025-09-01T05:43:43+00:00

Markdown Content:
Those vacations were the most intense I‚Äôve had in a while. Time off is always the chance to focus on building knowledge or skills, whether for personal enjoyment or for work. And this summer break was the perfect moment to disconnect from the hectic daily routine, the endless flow of emails and back-to-back meetings, and dive into introspection.

Our job is to look for AI-native companies (post-LLM startups), because we believe they are a different breed, born in a different world. Which begs the question: what about us? Why should funds be any less affected by this new paradigm? Could we be an AI-native fund, making moves as fast as the companies we invest in? And if we could start from scratch, where would we start?

[![Image 1](https://substackcdn.com/image/fetch/$s_!7xF8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34352ab3-3085-4ca3-8a0f-88290919b507_1308x1004.png)](https://substackcdn.com/image/fetch/$s_!7xF8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34352ab3-3085-4ca3-8a0f-88290919b507_1308x1004.png)

Hongdae in Seoul, known for K-pop culture, nightlife, trendy shopping‚Äîand now, vibe-coding ‚ú®.

August 2nd. I was alone in a tiny, windowless room in Hongdae, Seoul, while it was 35¬∫C outside: zero distractions, almost no family duty, and surrounded by konbinis open 24/7. It was the perfect setup to switch into full focus mode (some would call it *_berserk_* mode), locked in for almost 22 hours a day with bare sleep. I started testing nearly every tool, API, and flavor of AI coding - tap coding, vibe coding, agile coding, spec-driven coding, you name it - until I found my own pace and recipe. Then I literally went on a token frenzy, on a quest to turn our management company into an experimental sandbox with one clear goal: to make our workflow more efficient, more personalized, more agile, and more collaborative.

[![Image 2](https://substackcdn.com/image/fetch/$s_!X6qg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d1cb29-7605-4c22-8e14-9c631ccba50a_1786x992.png)](https://substackcdn.com/image/fetch/$s_!X6qg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d1cb29-7605-4c22-8e14-9c631ccba50a_1786x992.png)

Thank god, nobody can see my spaghetti code üôà

Sounds familiar, doesn‚Äôt it? It‚Äôs basically every company‚Äôs dream. And of course, it was our initial vision too, until reality struck. Four years ago, we started with a fancy yet incomplete home-made platform using Ruby on Rails, VueJS 2, and Postgres. I built it during the fundraising phase (yes, investors raise money too), but things went south pretty quickly once we began investing which left me absolutely no time to refine and upgrade the platform. A small fund faces the same workload and regulation as a large one, only with far fewer people to handle them.

I then decided to move to Airtable, which allowed me to add features quickly through scripting and required almost no maintenance. Our data feeding was inconsistent, and we believed a robust CRM was the answer. So we migrated to Pipedrive, with its out-of-the-box Google Suite integration, thinking this would finally bring auto-feeding.

[![Image 3](https://substackcdn.com/image/fetch/$s_!INL7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F617c0211-90d4-4e8d-9bb6-884a93fcae77_1600x1069.png)](https://substackcdn.com/image/fetch/$s_!INL7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F617c0211-90d4-4e8d-9bb6-884a93fcae77_1600x1069.png)

Airtable is a great tool, but even if you script it to death, it remains very rigid at its core.

We were dead wrong. A few months after deployment, I had opened Pipedrive exactly once. [Willy](https://www.linkedin.com/in/willybraun/), probably less. I believe the real issue lies in the CRM model itself. They are powerful tools when they are perfectly fed, but nobody wants to feed them. And nothing is worse than inconsistent structured data. I also believe that, even with absolute dedication, this state of perfection does not exist. I have wrestled with taxonomy my whole career. Movies at AlloCin√©. Games at Gamekult. Both at SensCritique. And later startups at daphni. It is a never-ending pain. Categories keep shifting labels, especially in our ecosystem. They are hard to define, and people rarely share the same framework or even the same depth of expertise.

In a world where a new model emerges each month, sometimes week, it became obvious we needed to move at the same speed, and be part of this evolution. Be leaner, yet enhanced. We now firmly believe we can do a better job while cutting team size by half. I‚Äôve built the foundations of the platform to make it happen (or not).

**Full disclaimer**: I had the luxury of starting from a blank page. I‚Äôm building a tool for a small, friendly audience with the goal of bringing perspective to our data, not a SaaS chasing product-market fit or built to scale teams worldwide. My experience is nothing like that of a typical engineer in a scaleup, where fucking it up carries far greater consequences. My codebase is also nowhere near the size most companies have to deal with. Let‚Äôs acknowledge that I‚Äôve already eliminated 90% of the difficulty and enjoy the best setup to vibe-code comfortably.

Here is my journey.

[![Image 4](https://substackcdn.com/image/fetch/$s_!kXTm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02a391a7-9e3f-43ba-aeef-887c1f896cee_4032x2448.jpeg)](https://substackcdn.com/image/fetch/$s_!kXTm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02a391a7-9e3f-43ba-aeef-887c1f896cee_4032x2448.jpeg)

My tiny crib in ÌôçÎåÄ for vibing hard

Back in Seoul, in my chicken coop, I decided to start from a blank page, leaving migration for later. My goal was first to be able to aggregate information in whatever shape and from whatever source it came. The good news is that LLMs are exceptionally good at handling large amounts of unstructured data. Even though we work in finance, our job does not always require ultra-precision or extreme consistency. What matters more is developing a sharp understanding of trends. We need to quickly spot data points in a vast, ever-shifting cloud to build conviction.

[![Image 5](https://substackcdn.com/image/fetch/$s_!ky2A!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08a9089-66cd-4425-b8c8-9990d62e0fd7_4320x2430.png)](https://substackcdn.com/image/fetch/$s_!ky2A!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08a9089-66cd-4425-b8c8-9990d62e0fd7_4320x2430.png)

How it started. Tho not the best idea overall.

Without overthinking or making a plan, I started with a Telegram agent connected to Pipedrive, since Telegram is our team‚Äôs hub and my biggest frustration was getting to data fast without Pipedrive‚Äôs (old fashioned) user‚Äôs experience. It worked so quickly that my ambitions grew (insert *_Villain‚Äôs evil laugh_* here). Why not build a full web interface to replace most of our use of Notion or Google Docs - keeping only the features we actually use, for a snappier, more comprehensive experience, and without being limited by someone else‚Äôs roadmap?

So I started laying the foundations of a polymorphic knowledge base, accessible from anywhere, able to ingest any kind of resource, and extract intelligence from it systematically. Articles, discussion logs, pitch decks, screenshots, curated newsletters, even a tweet or a Reddit thread, plus essentially every relevant email and document we wrote or received: the key is to collect at scale what we consider strong proxies for valuable information. This also includes our private Discord community, reg.exe, where 260 tech founders and AI leads from around the world discuss new trends, share insights, and celebrate achievements daily. Knowledge is everywhere, and we capture it automatically whenever we find it. And since AI agents aren‚Äôt flawless, I built our own Chrome extension, tightly integrated with our workspace, which lets us quickly start a note from a calendar meeting or flag a discussion if it hasn‚Äôt yet been detected by our crawlers.

This is our cloud of information, an unstructured stream of curated content from engineers or journalists, constantly on the edge of innovation, from which we extract structured, sourced and weekly memos to help us, our founders, and even our LPs nurture their decision-making process.

Let‚Äôs put aside purely deterministic needs (financial transactions, for instance) for a minute. Computers led us to treat information (processed, organized, meaningful facts) as data (raw, unorganized facts and figures, meaningless in itself), because that was the only form they could handle. Forcing knowledge into a rigid taxonomy has always been a nightmare. The moment someone decides to tag their ‚Äú_green_‚Äù companies as Climate Tech instead of Sustainable or Environment Friendly, your beautiful cog machine starts to cough. A human would naturally make the connection. A pre-LLM ERP or CRM would not unless specifically asked to. NLP, until recently, was little more than turning natural language into SQL queries: in other words, translating information back into data.

[![Image 6](https://substackcdn.com/image/fetch/$s_!mg9G!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0472769-c44a-4261-8674-c46a48ca908b_1364x1022.png)](https://substackcdn.com/image/fetch/$s_!mg9G!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0472769-c44a-4261-8674-c46a48ca908b_1364x1022.png)

LLMs are not perfect, but the same can be said when working with people. They‚Äôre not always consistent, though often in ways more subtle than binary code. Also, scaling vectors is far easier, and how we leverage them is getting insanely good at a rapid pace.

So I decided to embrace this philosophy for our intelligence. We would rather not always get the exact same result twice, but gain a more forgiving scope of knowledge, instead of letting something slip through the cracks just because of a new way of coining terms. The beauty is that it also allows our portfolio and our LPs to benefit from this knowledge base, and refine it as a group, not by a data scientist.

Frontend-wise, I spent countless hours iterating on our future workflow, meaning the proper user experience. That‚Äôs probably where the biggest chunk of tokens went, and I probably had a bit too much fun doing it üôà

Back then, we sketched doodles on paper, then moved to whatever design tool was trending at the time: Photoshop, Balsamiq, InVision, Sketch, then Figma. That step was usually unavoidable, because building in code used to take time: changing your mind on the flow meant losing hours, and your laziness (or your front-end developers team quitting) could easily cap your imagination. That‚Äôs why most design tools offered some way to showcase animations, with limited prototypes, dummy data, or _Lorem Ipsum_ gibberish.

[![Image 7](https://substackcdn.com/image/fetch/$s_!Gi3d!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F633a9765-8426-4c64-97e4-9b6623790ea8_1600x541.png)](https://substackcdn.com/image/fetch/$s_!Gi3d!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F633a9765-8426-4c64-97e4-9b6623790ea8_1600x541.png)

But I was alone, with less than 30 days to rebuild our team‚Äôs entire backbone. I was looking for a quick, painless way to turn that _meh_ design into something elegant without sinking time into it. First, I asked Claude to use [Google's M3](https://m3.material.io/) foundation (the latest Material Design), which was an improvement since it gave a bit of logic between screens, then I thought about sending screenshots of SaaS I find functional, minimal and pretty. So I grabbed a random screenshot of [Folk](https://www.folk.app/) in an article, shared it with Claude and let it work. My design was 80% done - a close-enough clone of a clean SaaS - in a single prompt, while I was sipping a Matcha Latte.

That blew my mind. Figma had been my best friend for years. I had it open even for the smallest, most trivial tasks, and suddenly it felt unnecessary for designing interfaces.

The design is only a tiny part of the user experience. And even if I have been working on web products my whole career since the late 90s, anticipating the user flow, writing all the specifications, designing every tiny bit of interface before launching the production has never been my forte.

[![Image 8](https://substackcdn.com/image/fetch/$s_!QYZY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8655b83e-5653-4bdd-b4f8-4499daf16865_1600x794.png)](https://substackcdn.com/image/fetch/$s_!QYZY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8655b83e-5653-4bdd-b4f8-4499daf16865_1600x794.png)

This new paradigm basically brought me back to enjoying the whole process like a [kid unwrapping a Nintendo Sixty-FOOOOOOOOOOUR](https://www.youtube.com/watch?v=pFlcqWQVVuU) on Xmas morning. If you have enough cash for the tokens (more on that later), you quickly feel like Neo.

Building with tokens unleashes your creativity: and you can spend as much time refining a feature as you want until it feels perfect to you. For instance, while working on the Chrome extension, I figured it might be cooler to turn it into a proper application with Electron, even though I‚Äôd never built one before. All I had to do was ask Claude Code to convert my half-baked extension into a proper Electron app (with a refactor and cleanup of the legacy, of course), and then enjoy another Matcha latte. Being able to change direction instantly, without reading a line of documentation, without hearing a sigh of disapproval, simply after a short discussion with your IDE, gives you a real god-mode feeling. [At least, at the beginning üòá]

In just a matter of days, I set the foundation for a Telegram assistant, a web app, and a desktop app, while ditching Figma, Notion, Slack and Pipedrive. Not bad for a fistful of tokens.

[![Image 9](https://substackcdn.com/image/fetch/$s_!dAZq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa30c9112-5184-4c3c-bab7-d813ae84ff0d_2702x1146.png)](https://substackcdn.com/image/fetch/$s_!dAZq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa30c9112-5184-4c3c-bab7-d813ae84ff0d_2702x1146.png)

Vibe-coding is also perfect for experimenting with tools to build your own. No need to dive into documentation‚Äîjust throw it into your IDE, ‚Äútalk through‚Äù whether it‚Äôs a good fit, and ask for alternatives. Once you‚Äôve made your pick, all that‚Äôs left is creating an account and dropping the `API_KEY` into your `.env` file.

So before I take you through the rest of my journey, here‚Äôs my current stack, you can give them a try yourself:

**üóÑÔ∏è [Supabase](https://supabase.com/)** for the structured data (and more). To be honest, I find their GUI cute but annoying and pretty slow. Some operations, such as ALTERs, take too long, even on empty tables, and using queries is always the best option. Still, Supabase offers out-of-the-box a myriad of practical features around the data stack to build faster. I use it for authentication, object hosting, image resizing, and I also rely on Supabase Edge Functions as a powerful extension to PostgreSQL triggers.

**üß† [Orq.ai](https://orq.ai/)** is our AI backbone. Since everything relies more or less on AI, I make extensive use of models and prompts as glue between bits of code. This glue needs to be evaluated and refined continuously, and Orq is our gateway, almost the sole entry point, enabling non-technical team members to make those changes seamlessly. From embedding, to hybrid search, information extraction, RAG: almost everything is _Orqed_.

**üîÆ [Mem0](https://mem0.ai/)** helps our agent (via Telegram for instance) to provide a conversational experience. It keeps memories as you use it, previous discussions, specific details, some preferences. Orq will add this layer soon. In the meantime, I am using Mem0 which works out-of-the-box. I never had to get back to it since the integration.

**üè† [Koyeb](https://www.koyeb.com/)** for hosting. I initially started the project in a serverless environment on Cloudflare Workers. It turned out to be a pain in the ass most of the time. Koyeb, on the other hand, delivers the smoothness ‚Äú_aux petits oignons_‚Äù of what serverless should feel like from a user‚Äôs perspective, with the advantage of a self-hosted environment and at the cost of bare metal. We also use their database service for some backlog features since disk storage is unlimited.

**‚öñÔ∏è [Shipfox](https://www.shipfox.io/)** is handling all our CI, and it‚Äôs absolutely critical as I enter the production phase. Building fast often means regressing twice as fast: LLMs have no pity for past code and lives in harmony with chaos. Shipfox doesn‚Äôt just cut down the cost of CI time, its dashboard gives me the visibility I need to spot flaky or unreliable tests. A common pain point as test suites grow, especially when you‚Äôre not the one writing them. Shipfox integrates seamlessly with GitHub Actions, and switching to it was as simple as changing a single line of YAML.

**üåé [Linkup](https://www.linkup.so/)** is our access to the outside world. All our notes and memos can be enriched with open data, and Linkup provides a simple yet powerful API that crawls and retrieves information in real time with the power of LLMs. This content can even be delivered in structured outputs, fitting seamlessly into templates. I‚Äôm probably only using 10% of Linkup‚Äôs potential, and there are plenty of features still to build with it.

**üêù [ScrapingBee](https://www.scrapingbee.com/)** is our scraper. Every link attached to our notes or memos, every newsletter we receive, every article we bookmark, and all content shared on our Discord is (or plan to be) automatically scraped and added to our knowledge base. ScrapingBee is powerful enough to bypass most trackers.

**üïµÔ∏è‚Äç‚ôÄÔ∏è [Notte.cc](https://www.notte.cc/)** is our smart scraper. It lets us navigate websites and extract information intelligently with prompts. Notte is freeing you from painful regular expressions, flimsy scripts and shitty parsers, and it behaves like a human would, only at scale.

[![Image 10](https://substackcdn.com/image/fetch/$s_!fh_D!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d7e1a32-9d5b-4091-bae0-49ea5adbe968_2160x1112.png)](https://substackcdn.com/image/fetch/$s_!fh_D!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d7e1a32-9d5b-4091-bae0-49ea5adbe968_2160x1112.png)

**üé® [Storybook](https://storybook.js.org/)** is a great way to keep the AI in check and establish a common language with it. It‚Äôs very popular among human teams, and collaborating with Claude is no different. You can have it generate stories for each component, giving you a clear, practical and beautiful portfolio to reference when requesting new styles and features. Thank you, [Robert Hommes](https://www.linkedin.com/in/rhommes/), for putting this on my radar. I wish I had started with it sooner.

**ü§ù [Tiptap](https://tiptap.dev/)** is a ‚Äú_headless, framework-agnostic rich text editor_‚Äù built on top of [ProseMirror](https://prosemirror.net/), offering an out-of-the-box Notion-like experience. You can use it as an open-source library, and it already does a great job: pretty, highly configurable, and with a cloud-hosted version that adds powerful live-collaboration features. [Karim Matrah](https://www.linkedin.com/in/karim-matrah) from [Contrast](https://www.getcontrast.io/) also shared great alternatives in that space: [BlockNoteJS](https://www.blocknotejs.org/) and [Liveblocks](https://liveblocks.io/).

**üß† [Lettria](https://www.lettria.com/)**will soon upgrade our standard RAG into a Graph RAG. By combining graph capabilities with the power of vectors, we‚Äôll be able to extract information with much greater accuracy and be (almost) free from hallucinations. We are currently carefully selecting the content that will serve as the foundation for our ontology.

**üîé [Meilisearch](https://www.meilisearch.com/)** for AI search. Honestly, [Orq.ai](https://orq.ai/) is already handling perfectly the hybrid search, but I‚Äôve heard so many great things about Meilisearch‚Äôs user experience (ping [Gilles Samoun](https://fr.linkedin.com/in/gilles-samoun)) that I decided to connect their API to experiment with it. I won‚Äôt keep it in my stack, but developers looking exclusively for a search engine API should definitely give it a try.

**üõü [Plakar](https://plakar.io/)**, for peace of mind. History has shown [time](https://www.youtube.com/watch?v=pKh5fNuj2-w) and [again](https://www.youtube.com/watch?v=gSrnXgAmK8k) that [shit happens](https://www.datacenterdynamics.com/en/analysis/ovhcloud-fire-france-data-center/), no matter how big you are, no matter how good your infrastructure or code may be. And since we‚Äôre neither big nor am I particularly dedicated, focused, or talented, I need something both bulletproof and effortless to set up and restore. Therefore, Plakar is the way.

**üéõÔ∏è [Alpic](https://alpic.ai/)** to tinker a bit with MCP, integrate parts of our platform into Claude and ChatGPT directly, replace our Telegram agent, and see how far we can push the boundaries.

I started this journey with [Cursor](https://cursor.com/), tried many other flavors of VS Code (see below: _Game the Same, Just Got More Fierce_) but spent most of my time with Claude Code. All these tools are absolutely magic, and the choice is (almost) entirely subjective.

When using Cursor, I was still a bit hands on. But quickly, I‚Äôve switched to full prompt and probably wrote fewer than legit ten lines myself (changing a few Tailwind tags don‚Äôt count). 99.9% of the coding was done through AI. That doesn‚Äôt mean it was 99.9% painless. Hell no. It ain‚Äôt all magic: programming models are a great tool for people with coding and good technical architecture knowledge. People who are willing to dive into the weeds when needed. If you know nothing and don‚Äôt understand what the AI is telling you, and you can‚Äôt guide it from time to time, you can quickly end up in a costly spiral of death, burning tokens (and your mortgage savings) while Claude loops endlessly over something stupid and/or impossible. And this happens A LOT.

[![Image 11](https://substackcdn.com/image/fetch/$s_!hd-l!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44a3fd9c-a089-4231-b2e4-2a088b65dbd5_2180x1140.png)](https://substackcdn.com/image/fetch/$s_!hd-l!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44a3fd9c-a089-4231-b2e4-2a088b65dbd5_2180x1140.png)

LLMs are not (yet) autonomous engineers. So the larger the codebase grows, the more the IDE requires precise instructions, clear scoping, and close monitoring to avoid damaging the foundation. Keep in mind: if LLMs are amazing at building things fast, they carry just as much destructive power, if not more. So far, Claude did 80% of the heavy lifting for me. The remaining 20% demanded far more guidance and were sometimes so painful, so extreme, it felt like being a babysitter on the verge of murder. I could‚Äôve written more code, but I find it difficult to co-write with an AI, and I decided to focus on the logic and the data structure instead.

People say a good prompt is the path to success. It is true, but to be fully honest, I was not obsessed with it. At first, I used Claude Desktop to draft a plan before pasting it into Claude Code (benchmarks say that you need to feed models with their own dog food). I eventually settled into a half-baked routine: putting Claude in ‚Äúplan/pause mode,‚Äù where the model is only allowed to browse files, do its research, prepare a strategy, and throw out ideas without discrimination: something major, structural, then 10 useless details as they come. Then I let it refine the plan through discussion before giving it a go. It‚Äôs a messy back-and-forth where I let the structure emerge with the flow. Hardly the best recipe for clean code straight out of the box, and some people far smarter than me have turned prompting into a science (check out [Gabriel Olympie](https://www.linkedin.com/in/gabriel-olympie-ba8b6a103/)‚Äôs [PromptServer](https://github.com/gabrielolympie/PromptServer), for instance). But the good thing about vibe-coding is that nobody‚Äôs there to judge you.

[![Image 12](https://substackcdn.com/image/fetch/$s_!_E69!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8f1a4b8-0e67-424b-bb9c-2711c9527cae_2094x846.png)](https://substackcdn.com/image/fetch/$s_!_E69!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8f1a4b8-0e67-424b-bb9c-2711c9527cae_2094x846.png)

Sadly, going full-throttle on vibe-coding comes with more than just the cost of tokens. Soon enough, you feel like Dr. Frankenstein, stitching together isolated bits of code. And the more you build, the heavier the weight of technical debt becomes, revealed through hundreds of inconsistencies. Some are visual (different button styles, mismatched font sizes and colors you never asked for), others functional (z-index chaos, redundant decision trees across the repositories leading to inconsistent behavior). Even if you‚Äôre not the one coding every line, you can still feel your amazing project starting to drift south after only a few days. Think of your AI copilot as a junior developer who behaves like all LLMs: very proactive (sometimes too much), eager to please, a bit too obsequious, and occasionally forgetful.

[![Image 13](https://substackcdn.com/image/fetch/$s_!q5-3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F285ad649-e9cf-4369-9987-8a4f2d042754_1302x1132.png)](https://substackcdn.com/image/fetch/$s_!q5-3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F285ad649-e9cf-4369-9987-8a4f2d042754_1302x1132.png)

The way to mitigate it is the same as with humans: (ask it to) write logs for debugging. (Ask it to) write specifications once you‚Äôre satisfied with a result. And (ask it to) document thorough postmortems while the context is still fresh, so it doesn‚Äôt fall into the same pitfall twice. This becomes even more useful when you have multiple apps and repositories, as I do. They all need to communicate heavily through APIs. The more context you give the AI, the more efficient it becomes, and the happier you‚Äôll be.

On top of these good practices, nothing beats proper testing, especially on the backend. You can survive a missing overlay or a visual inconsistency, but you don‚Äôt want to risk losing real information or leaving a huge backdoor open. In a way, the major discovery is that whether it‚Äôs a human or a machine building, the guardrails stay the same.

For almost an entire month, Anthropic unexpectedly allowed me to use the $200 Max 20x plan from Claude Desktop on Claude Code way beyond any reasonable level of consumption. Between August 4th and 22nd, my usage added up to roughly $2.6k in token value. Then I was notified that I‚Äôd be downgraded from Opus to Sonnet (The quota system keeps changing, and the latest update, I believe, provides 40 hours of Opus and 480 hours of Sonnet per week with Max 20x) with both speed and quality taking a hit. It feels like that first $200 entry point is a first dose of crack. Claude is the pusher, me the drug fiend. Now, to keep the rush going, I need to use the API and pay per usage instead of a flat monthly fee. In that mode, you‚Äôre basically topping up $100 multiple times a day. At my pace, that meant about once every three hours of work. Was it worth it? [You‚Äôre goddamn right](https://www.youtube.com/watch?v=G6ozHscfyfY)! Even if I could have made my token consumption far more efficient (see below: _Garbage In, Garbage Out_).

[![Image 14](https://substackcdn.com/image/fetch/$s_!jIuF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc20920c1-a59f-4df1-bba0-d55277546e03_1200x800.png)](https://substackcdn.com/image/fetch/$s_!jIuF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc20920c1-a59f-4df1-bba0-d55277546e03_1200x800.png)

Claude, confidently waiting for me to come back for more. He knows.

In just a few weeks, I‚Äôve already cycled through five different tools, hopping from one to the next without needing to configure parameters or adjust the way I prompt. And that‚Äôs not even counting the asynchronous agents I briefly tested, like [Jules](https://jules.google.com/) (Google Labs) or the very early [Ariana.dev](https://ariana.dev/). By contrast, in my 25 years in tech I‚Äôve only seriously used five code editors. These days, I can barely tell you what I‚Äôll be using next week.

[![Image 15](https://substackcdn.com/image/fetch/$s_!_rOs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcccb54a6-9486-4c69-a3f2-2229a6752439_2012x290.png)](https://substackcdn.com/image/fetch/$s_!_rOs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcccb54a6-9486-4c69-a3f2-2229a6752439_2012x290.png)

Within a few days, Alibaba released [Qoder](https://qoder.com/), another promising VS Code fork. They launched with a free plan capped at ‚Äú2000 credits‚Äù (whatever that really means), clearly aiming to capture a share of the agentic coding market. [Kilo Code](https://kilocode.ai/) followed, announcing - like many others - a 7 day [uncapped free access to Grok Code Fast](https://blog.kilocode.ai/p/grok-code-fast-get-this-frontier-ai-model-free) (aka Sonic). Meanwhile, OpenAI announced significant improvements to [Codex](https://openai.com/codex/) - after a rather chilly reception - reportedly leading to [people ditching Anthropic‚Äôs Opus](https://x.com/VictorTaelin/status/1958543021324029980), still considered the top performer but at a steep cost.

And that‚Äôs just one week in the coding tool landscape.

[![Image 16](https://substackcdn.com/image/fetch/$s_!tXi2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6832d91-c836-44d2-9a92-066c2ec9108e_1578x1056.png)](https://substackcdn.com/image/fetch/$s_!tXi2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6832d91-c836-44d2-9a92-066c2ec9108e_1578x1056.png)

I‚Äôm going to repeat myself, but it‚Äôs worth reiterating that starting from a blank page is very different from dealing with legacy code in a stressed production environment. After just a few weeks, I felt the urge to clean up and streamline, and I spent days refactoring my spaghetti code with Claude. For instance, the mix of Material Design, migrated half-way to Tailwind‚Äôs standard ended up in a complete abomination. But even in this case, I managed to (painfully) prompt my way out.

Overall, LLMs aren‚Äôt yet at the point where they can replace all engineers. But I don‚Äôt doubt they will be soon enough, and in the meantime, they