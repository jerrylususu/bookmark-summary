# If you are good at code review, you will be good at using AI agents
- URL: https://www.seangoedecke.com/ai-agents-and-code-review/
- Added At: 2025-09-20 14:00:07

## TL;DR
文章强调，擅长代码审查的开发者能更好地监督AI编程助手（如Copilot）的输出，避免其产生无效或复杂的设计，从而提高开发效率和代码质量。当前AI工具尚未成熟，仍需人类主导判断和监督。

## Summary
文章探讨了代码审查能力与有效使用AI编程助手之间的紧密联系，并认为擅长代码审查的开发者在使用AI工具上更具优势。主要内容如下：

**1. 核心观点**
- AI代码生成工具（如Claude Code、Codex、Copilot）擅长生成大量代码，但缺乏资深工程师的判断力，容易陷入错误的设计决策。因此，用户需要像代码审查一样监督AI，避免其产生低效或复杂的解决方案。
- 如果用户不进行监督，AI可能浪费时间和资源，导致代码库变得难以维护。

**2. 实际案例**
- 作者分享了两个项目经验：
  - 在VicFlora Offline项目中，AI试图逆向工程前端代码，但作者发现存在更简单的数据获取方式，从而节省了时间。
  - 在另一个学习应用项目中，AI建议构建复杂的后台任务系统，而作者通过推动简单的前端非阻塞请求，避免了过度设计。
- 这些例子说明，AI工具类似于“热情但缺乏经验的初级工程师”，需要用户引导以避免架构错误。

**3. 代码审查的角色**
- 有效的代码审查不应只关注代码细节（如函数命名或语法优化），而应进行“结构性审查”：考虑代码的上下文、可重用性和整体设计，以简化解决方案。
- 用户类型对AI使用的影响：
  - 过于挑剔的审查者可能陷入细节调整，错失指导AI避开错误架构的机会。
  - 草率认可的审查者可能过度信任AI，导致类似 onboarding 初级工程师时的问题，无法有效管理AI的输出。

**4. 对AI能力的当前评估**
- 作者认为，当前AI工具尚未达到“无所不能”的水平，使用模式更接近“半人马棋”（人机协作），其中人类提供判断和监督。
- 与乐观的AI支持者观点不同，作者强调AI工具仍需密切监督，而非完全依赖。擅长代码审查（即评估软件方法合理性）的能力直接提升AI使用效果。

**5. 未来展望**
- 作者提出思考：从2022年到2025年，AI工具是否像人类一样“成长”？未来AI可能更像有经验的工程师，但目前仍需人类主导。
- 使用多种AI工具是作者工作的一部分，旨在保持对不同方案的了解。

总体而言，文章强调代码审查技能是有效利用AI编程助手的基石，能够帮助用户识别和纠正AI的错误倾向，从而提高开发效率和代码质量。
