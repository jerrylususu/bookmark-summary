# Why do AI models use so many em-dashes?
- URL: https://www.seangoedecke.com/em-dashes/
- Added At: 2025-10-30 14:05:39
- [Link To Text](2025-10-30-why-do-ai-models-use-so-many-em-dashes_raw.md)

## TL;DR
AI模型过度使用破折号的现象主要源于训练数据的变化。GPT-4等模型为获取高质量数据，数字化了大量19世纪末到20世纪初的书籍，这些历史文本中破折号使用率较高，导致模型习得这一习惯。强化学习人类反馈或AI内容循环也可能加剧此现象，但核心原因在于训练数据的历史语言风格影响。

## Summary
AI模型过度使用破折号的现象已成为其文本的显著特征，甚至导致真实人类为避免被误认为AI而减少使用。尽管用户尝试通过提示词限制模型使用破折号，但往往失败。文章探讨了多种可能解释，并最终提出一个较为合理的假设。

首先，作者否定了三种常见解释：
1. **训练数据模仿**：认为破折号在正常英文中本就常见，但若如此，AI使用破折号不应如此引人注目。
2. **语法灵活性**：认为破折号能保持语义开放性，但其他标点（如逗号）同样灵活，且模型生成文本未必出于“保险”策略。
3. **简洁性偏好**：认为破折号节省标记（token），但实际替换为逗号 equally 简洁，且模型若追求简洁，更应减少冗长内容。

其次，作者考察了**强化学习人类反馈（RLHF）的影响**。由于RLHF工作多在非洲（如肯尼亚、尼日利亚）进行，而非洲英语常用“delve”等华丽词汇，这可能解释GPT-4o的用词偏好。但数据分析显示，尼日利亚英语的破折号使用率（0.022%）低于一般英语（0.25%-0.275%），因此破折号滥用与RLHF地区方言无关。

关键假设集中在**训练数据的变化**：
- GPT-3.5几乎不用破折号，而GPT-4o使用量增加10倍，同期Anthropic和谷歌模型也出现类似现象。
- 2022年后，AI实验室为获取高质量数据，开始数字化大量印刷书籍，而非仅依赖网络数据或盗版书（后者偏向当代流行内容）。
- 历史研究表明，破折号使用率在1860年达到峰值（约0.35%），随后下降。数字化书籍可能包含更多19世纪末至20世纪初的文本，这些文本破折号使用率比当代高约30%。
- 因此，模型从这些历史书籍中学习了破折号的使用习惯，导致生成文本中破折号泛滥。

作者也指出其他可能性：
- 破折号可能因RLHF评分者认为其更口语化而被强化，形成循环偏好。
- 部分现象可能源于模型训练时吸收了其他AI生成的内容。

最终，作者强调该结论仍属推测，需OpenAI内部人员验证。同时提出疑问：若模型学习了19世纪文本风格，为何生成文本仍显现代？可能模型仅吸收了标点等片段，而非整体风格。
