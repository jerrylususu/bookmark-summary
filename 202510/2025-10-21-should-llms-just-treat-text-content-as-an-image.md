# Should LLMs just treat text content as an image?
- URL: https://www.seangoedecke.com/text-tokens-as-image-tokens/
- Added At: 2025-10-21 13:38:51
- [Link To Text](2025-10-21-should-llms-just-treat-text-content-as-an-image_raw.md)

## TL;DR
光学压缩将文本转为图像输入多模态大模型，有望提升数据处理效率。这种图像令牌比文本令牌更高效，类似人类视觉处理方式。虽有应用探索，但训练难度与效果仍需验证，潜力待进一步研究。

## Summary
这篇文章探讨了将文本内容视为图像（即“光学压缩”）对大型语言模型（LLM）的潜在影响。主要论点如下：

- **光学压缩的概念**：基于DeepSeek的OCR论文，模型可以从单个图像令牌中提取约10个文本令牌，且准确率接近100%。这意味着图像的内部表示比文本更高效，可能使模型在推理时处理更多数据（例如，将文本转换为图像后再输入模型，可提升数据输入效率）。
- **实际应用与前景**：已有公司和服务尝试将文档转换为图像供多模态LLM处理，并出现了相关开源项目和基准测试。论文还提出，可动态降低长文本中旧图像的清晰度以节省存储，类比人类记忆的模糊化过程。
- **工作原理分析**：虽然原始图像文件比文本大得多，但图像令牌在模型内部是连续且高维的，能表达更丰富的信息；而文本令牌是离散的，嵌入空间有限，导致信息表示效率较低。这种差异使图像令牌可能更高效。
- **与人类认知的类比**：人类通过视觉（图像）或听觉处理文本，而非直接消费文本内容。将文本视为图像可能解锁新的处理方式，如更好理解段落结构或快速浏览文档。
- **挑战与不确定性**：训练纯图像文本模型存在困难，例如如何分割图像单词并预测下一个单词。若输出仍用文本令牌，模型可能退化为普通LLM。目前，该想法尚未成为主流，实际效果需进一步验证。

总体而言，光学压缩是一个有潜力的方向，但需更多研究来评估其可行性和优势。
