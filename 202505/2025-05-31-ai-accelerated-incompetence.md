# AI: Accelerated Incompetence
- URL: https://www.slater.dev/accelerated-incompetence/
- Added At: 2025-05-31 11:41:36

## TL;DR


过度依赖大语言模型（LLMs）将加剧技术债务、弱化开发者能力并侵蚀代码质量，因其无法保障输出正确性、识别需求缺陷或控制复杂度增长。软件工程的核心价值在于人类构建理论、管理程序熵及批判性思维能力，唯有将AI作为辅助工具，并持续精进工程技能，才能避免沦为技术婴儿化与维护困境的牺牲品。

## Summary


本文探讨了软件工程中过度依赖大语言模型（LLMs）如何加速能力退化，并强调人类批判性思维不可替代。主要内容如下：

**过度依赖LLMs的风险**：
1. **输出风险**：LLMs可能生成编译错误或隐含逻辑缺陷的代码，尤其当提示者无法有效评估输出时（如非开发人员直接生成代码）。
2. **输入风险**：LLMs无法质疑低效或有缺陷的请求，例如开发者要求“提供线程安全列表的C#实现”时，LLMs不会指出应优先使用现成库（如`System.Collections.Concurrent`），而是可能输出冗余代码。
3. **未来Velocity风险**：LLMs快速生成的代码可能导致技术债务激增，代码质量迅速下降，如同“囤积强迫症患者家中混乱不堪的内部环境”。
4. **用户婴儿化**：依赖LLMs会削弱个人和组织的思维能力：
   - 资深工程师因减少实践机会失去问题解决与批判性思考能力（微软研究指出，AI驱动的自信可能以牺牲批判性思维为代价）；
   - 初级工程师无法形成基础能力，最终难以培养下一代新人。
5. **失去创作乐趣**：开发者反馈AI破坏其沉浸式创作状态，生成的代码难以阅读和维护。

**LLMs无法替代的人类核心能力**：
1. **程序理论（Program Theory）**：编程的本质是构建共享的设计理论，而非单纯编写代码。团队若拥有对程序设计的理解（理论），维护时效率更高（参考Peter Naur的理论构建观点）。
2. **程序熵（Program Entropy）**：程序维护必然增加复杂性（熵）。人类能通过符合设计的修改减缓复杂性增长，而LLMs作为文本预测工具，易引入不必要的复杂变化（引用Fred Brooks的复杂性理论）。

**结论**：
- 过度依赖LLMs将导致长期成本上升，如技术债务和维护困难，企业需谨慎避免成为AI滥用的牺牲品。
- 人类在软件工程中的核心价值在于构建理论、管理复杂性及深度思考能力，这些无法被AI替代。
- 正确的应用方式是将AI作为工具而非依赖，持续提升工程技能与批判性思维，方能抵御AI带来的冲击。
