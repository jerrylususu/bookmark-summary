Title: The Slow Collapse of Critical Thinking in OSINT due to AI

URL Source: https://www.dutchosintguy.com/post/the-slow-collapse-of-critical-thinking-in-osint-due-to-ai

Published Time: 2025-04-02T11:41:14.187Z

Markdown Content:
       


top of page

























  

Dutch OSINT Guy 
Nico Dekens










Home



About



Events



Blog




More


Use tab to navigate through the menu items.
Book Nico Dekens





































All Posts
Cryptography
OSINT
analysis
audio
AI





Search














The Slow Collapse of Critical Thinking in OSINT due to AI



Nico Dekens | dutch_osintguy
7 days ago
10 min read


Updated: 2 minutes ago








OSINT used to be a thinking game. Now itâ€™s becoming a trusting game and that should terrify you.






Iâ€™ve seen it firsthand, analysts running solid investigations, then slowly shifting more and more of the thinking to GenAI tools. At first, itâ€™s small. You use ChatGPT to summarise a document or translate a foreign post. Then itâ€™s helping draft your reports. Then itâ€™s generating leads. And eventually, youâ€™re not thinking as critically as you used to. Youâ€™re verifying less, questioning less, relying more.


We tell ourselves weâ€™re â€œworking smarter.â€ But somewhere along the way, we stop noticing how much of the actual thinking is being offloaded.






This isnâ€™t a rant against AI. I use it daily, ChatGPT, Copilot, Claude, Gemini. Theyâ€™re in my workflow like everyone elseâ€™s. But the tradecraft is slipping. Analysts are skipping the hard parts. Theyâ€™re trusting GenAI to do the heavy cognitive lifting, and itâ€™s changing how we operate at a foundational level.






When OSINT becomes too easy, too efficient, too comfortableâ€¦ you should be worried. Tradecraft isnâ€™t just about speed, itâ€™s about judgment. And judgment doesnâ€™t come from a language model. If we keep going down this path without pushing back, without actively preserving the critical habits that define our profession, we risk becoming operators of automation instead of investigators.






This blog is a wake-up call. For myself. For anyone working in OSINT. For the people teaching it, and the people just getting started. If we donâ€™t reclaim the thinking side of this game, weâ€™ll lose the game entirely.










The Study That Should Alarm You






In early 2025, a team from Carnegie Mellon and Microsoft Research published something every OSINT analyst should read, but most havenâ€™t. It was a large-scale survey of 319 knowledge workers using GenAI tools like ChatGPT, Copilot, Claude, and Gemini in their daily work.






What they found is a warning shot.






The study revealed a clear pattern: the more confidence users had in the AI, the less they thought critically. In contrast, the more confident they were in themselves, the more likely they were to question the output, verify the information, and think deeply about the task.






Let that sink in: Confidence in AI replaces confidence in self and with it, the thinking disappears.






Hereâ€™s the punchline:






High trust in GenAI consistently led to reduced critical thinking and less cognitive effort across the board.






Participants werenâ€™t lazy. They were experienced professionals. But when the tool responded quickly, confidently, and clearly they stopped doing the hard part. They stopped questioning. Stopped verifying. Stopped applying the mental friction that separates automation from investigation.






The scary part is that many users still believed they were thinking critically, because GenAI made them feel smart.






The researchers saw a new type of behavior emerge:






â€¢ Instead of forming hypotheses, users asked the AI for ideas.


â€¢ Instead of validating sources, they assumed the AI had already done so.


â€¢ Instead of assessing multiple perspectives, they integrated and edited the AIâ€™s summary and moved on.






This isnâ€™t hypothetical. This is happening now, in real-world workflows. And if youâ€™re in OSINT, you know how dangerous that is.






In our line of work, you canâ€™t afford false confidence. You canâ€™t afford a hallucinated source, a mistranslated post, or a manipulated summary. But the more trust you place in GenAI, without friction, without skepticism, the more you risk exactly that.


The study didnâ€™t focus on OSINT directly. But it doesnâ€™t have to. The findings hit home harder here than anywhere else. Because if we lose critical thinking in this field, we donâ€™t just lose accuracy, we lose integrity.






What This Means for OSINT










In OSINT, we deal in fragments. Nothing is handed to us neatly. We build context from chaos: tweets, photos, forums, leaks, metadata, satellite images, dead links, weird file names. Every good analyst knows that the work isnâ€™t just collecting data. Itâ€™s thinking with it.


Thatâ€™s whatâ€™s at risk.


The Lee et al. study wasnâ€™t about OSINT specifically, but it described exactly whatâ€™s happening in OSINT shops, government teams, threat intel units, and open-source communities around the world. The creeping shift from thinking to prompting, from analyst to editor. Letâ€™s talk real.










Real-World OSINT Scenarios Affected by GenAI Complacency






Scenario 1: Image Verification






You upload a protest photo into a tool like Gemini and ask, â€œWhere was this taken?â€ It spits out a convincing response: â€œParis, near Place de la RÃ©publique.â€ It sounds right. You move on.






But a trained eye would notice the signage is Belgian. The license plates are off. The architecture doesnâ€™t match. You trusted the AI and missed the location by a country.






Scenario 2: Person of Interest Profile






You use Claude to summarize a personâ€™s online presence. It generates a clean narrative: activist, tech worker, harmless. But it completely omits their links to far-right forums because the model didnâ€™t surface the fringe platforms. You never check. That person ends up speaking at a sensitive public event.






Scenario 3: Disinformation Campaign Detection






You feed a stream of Telegram messages into ChatGPT and ask for â€œsummary and patterns.â€ It flags some keywords, but misses the subtle linguistic shift that points to a known Russian influence cell, something only a trained mind would notice by comparing phrasing across sources. But youâ€™ve stopped reading the raw content. You trusted the summary






These arenâ€™t edge cases. These are plausible daily failures in modern OSINT workflows.


And hereâ€™s the kicker: in each case, the analyst didnâ€™t fail because of bad intent or laziness. They failed because the tools were just good enough to feel trustworthy and just wrong enough to be dangerous.






AI doesnâ€™t break OSINT. But unquestioned AI does.






When analysts become dependent on outputs instead of building their own reasoning, they lose what makes OSINT powerful: the ability to interpret, interrogate, and pivot. You canâ€™t pivot from a hallucinated answer. You canâ€™t investigate a lie you believed too quickly.


GenAI doesnâ€™t understand context, risk, geopolitical nuance, or how bad actors use language to hide intent. It doesnâ€™t know when to doubt itself. Thatâ€™s your job and too many are forgetting that.










The Creeping Death of Tradecraft






Tradecraft isnâ€™t just a list of tools. Itâ€™s a way of thinking. Itâ€™s the habit of looking again when something feels off. Itâ€™s verifying metadata, cross-checking timestamps, spotting a street sign that doesnâ€™t match the language in the caption. Itâ€™s the instinct to question the obvious.






And that instinct is quietly dying.






Not because analysts are getting lazy, but because AI is making the job feel easier than it actually is. Youâ€™re still working. Youâ€™re still clicking. But the mental friction is gone.






That friction used to be where tradecraft lived.






Letâ€™s get brutally honest about whatâ€™s happening:










Then vs. Now: What OSINT Analysts Used to Do






Then:


â€¢ Saw a blurry image, opened it in three tools, zoomed in, rotated it, looked for EXIF, cropped landmarks, and reverse searched five times.


â€¢ Read a social post in broken Russian, translated it manually, checked slang, looked up associated hashtags, and verified the accountâ€™s activity history.


â€¢ Traced a domain name through WHOIS, looked at subdomains, searched for reused infrastructure, and mapped out connected email addresses.






Now:


â€¢ Paste the image into the AI tool, read the suggested location, and move on.


â€¢ Dump a thread into ChatGPT for summary.


â€¢ Ask Gemini, â€œWho runs this domain?â€ and accept the top-line answer.






This isnâ€™t about nostalgia, itâ€™s about recognising a dangerous shift in behavior. The more we â€œtrust the tool,â€ the less we build the skills that make the tool useful. Weâ€™re automating our edge away.


And GenAI isnâ€™t just fast, itâ€™s persuasive. It writes with confidence. It fills in gaps. It doesnâ€™t hesitate, and that creates a dangerous illusion of accuracy. Analysts are making decisions based on language model confidence, not evidence. Itâ€™s happening slowly. Silently. Like rot.










What Dies When Tradecraft Goes Passive?






â€¢ Contextual reasoning: spotting when something doesnâ€™t add up, even if it â€œlooks right.â€


â€¢ Cross-source verification: confirming a fact with at least two or three unrelated sources.


â€¢ Hypothesis testing: building and breaking possible explanations for what youâ€™re seeing.


â€¢ Refusal to settle: the instinct to keep digging, even when the AI gave you a plausible answer.






Without these, OSINT becomes automated guesswork with a shiny UI.






And make no mistake, bad actors know this. Theyâ€™ll test your tools. Feed them poisoned content. Exploit AIâ€™s tendency to repeat, simplify, and hallucinate. If your entire workflow is built on trust in the machine, youâ€™re walking into a trap.






Tradecraft is slow. Tradecraft is uncomfortable. Tradecraft is what keeps your work accurate, defensible, and trusted. Without it, youâ€™re just another person typing prompts and hoping for truth.










The New Role of the Analyst: AI Overseer, Not AI Believer






Hereâ€™s the truth: GenAI is here to stay. Itâ€™s not going away. And for OSINT, itâ€™s not the enemy. But it is a liability, if you donâ€™t treat it like one.


The analystâ€™s job has changed. Or rather, it needs to.


Youâ€™re no longer just a researcher, a data miner, a pattern spotter.


Youâ€™re now an AI overseer. A challenger. A verifier. A filter.






If you treat ChatGPT, Claude, Gemini, or Copilot as reliable assistants, theyâ€™ll eventually lead you to errors, because theyâ€™re not assistants. Theyâ€™re high-speed, high-confidence content engines with zero lived experience and no sense of consequence. Your role is to make sure they donâ€™t get away with anything.






How the Analyst Mindset Must Shift:









Old Role

New Role

Ask AI a question

Interrogate AI answers

Accept summaries

Dissect summaries

Use suggestions

Break suggestions apart

Trust clean answers

Trace dirty origins

Generate profiles

Validate narratives

Draft and ship

Draft, rip apart, and rebuild


Youâ€™re not there to be impressed by what the model says. Youâ€™re there to break it, test it, and decide what survives. That means:






â€¢ Running the AIâ€™s claim through manual OSINT methods


â€¢ Fact-checking what it didnâ€™t cite


â€¢ Comparing AI output against real-world source behavior


â€¢ Asking â€œWhat isnâ€™t it telling me?â€






AI tools should trigger suspicion, not satisfaction. Every time the answer seems too clean, too simple, too aligned with your bias, you should feel that OSINT tingle in your brain: â€œWaitâ€¦ prove it.â€ 


You wouldnâ€™t blindly trust a witness in an investigation just because they speak confidently. Donâ€™t trust a model either. Itâ€™s not about being anti-AI. Itâ€™s about preserving cognitive sovereignty. Because the moment you let the model do the thinking for you, you stop being an investigator, you become an operator.










Reviving Critical Thinking in the AI Era






If critical thinking is dying, itâ€™s not because we donâ€™t care, itâ€™s because we stopped practicing it. The good news? You can take it back. But it wonâ€™t happen by accident. It requires intention.






Hereâ€™s how OSINT practitioners can stay sharp in a GenAI world:






Introduce Friction on Purpose






GenAI is fast. Thatâ€™s the trap.


You need to slow yourself down (deliberately) before trusting anything it gives you.






Tactics:


â€¢ Pause and ask: What sources would I have checked without AI? Go check them anyway.


â€¢ Require yourself to find one contradiction to the AIâ€™s output before accepting it.


â€¢ Use a second model (Claude, Gemini, etc.) and force a contradiction: â€œGive me the opposite interpretation.â€










Rebuild Your Source Discipline






GenAI doesnâ€™t cite like an OSINT analyst does. So donâ€™t let it train you into laziness.






Tactics:


â€¢ If a model gives you a name, quote, link, or claim, donâ€™t just Google it. Trace it.


â€¢ Keep a side-by-side log: AI output vs. verified source. Whereâ€™s the gap?


â€¢ When using summaries, always open the original material anyway. Always.










Use AI as a Thought Partner, Not an Oracle






Treat GenAI like a junior analyst: decent ideas, but needs supervision.






Tactics:


â€¢ Ask it to argue against your current hypothesis.


â€¢ Feed it your working notes and ask, â€œWhatâ€™s missing? What assumptions am I making?â€


â€¢ Use it to simulate perspectives, not to define reality.










Cross-Model Interrogation






Different models have different blind spots. Use that.






Tactics:


â€¢ Ask the same question across ChatGPT, Claude, Gemini, and Copilot. Compare outputs.


â€¢ Note contradictions. Investigate why they differ.


â€¢ Treat divergence as signal, not noise.










Force Failure






If youâ€™re not actively trying to break the model, youâ€™re not using it critically.






Tactics:


â€¢ Intentionally feed it misleading prompts and watch what it hallucinates.


â€¢ Track how it behaves under ambiguity, contradiction, or incomplete data.


â€¢ Learn its failure modes and build your tradecraft to fill the gaps.










Keep Doing the Hard Stuff






The tools should speed you up, but they should never replace the hard parts.






Tactics:


â€¢ Geolocate manually before checking with AI.


â€¢ Write your own summary before reading the AIâ€™s.


â€¢ Build your own profile first, then ask the AI to challenge it.










The Quiet Collapse and How We Fight It






The fall of critical thinking in OSINT wonâ€™t come with a bang. Itâ€™ll come quietly. Itâ€™ll look like faster reports. Cleaner narratives. Fewer questions asked. Itâ€™ll feel efficient. Itâ€™ll look like progress.


Until it isnâ€™t.


Until you miss the real location. Trust the wrong source. Assume the wrong intent. Attribute the wrong actor. And by then, your tradecraft wonâ€™t save you, because you wonâ€™t have practiced it.






This is how it starts. It starts with trusting summaries. With accepting citations you didnâ€™t check. With replacing your judgment with something that sounds like judgment. The collapse wonâ€™t be obvious. It will feel convenient. Thatâ€™s what makes it so dangerous. But hereâ€™s the part that matters: itâ€™s reversible.






You donâ€™t need to ditch GenAI. You need to confront it. Challenge it. Break it. Question it. Use it, but never trust it without a fight. Youâ€™re not just a user of tools. Youâ€™re an investigator.






You think critically. You trace evidence. You challenge assumptions. Thatâ€™s the job.


Donâ€™t let the machine do the thinking for you.










Bonus: OSINT Anti-Overreliance Checklist






Keep this near your screen. Use it when GenAI enters your workflow.






âœ… Did I verify osint-vs-ai the original source of any AI output?


âœ… Did I consult non-AI sources before accepting the answer?


âœ… Did I challenge the output with a counter-hypothesis or alternate model?


âœ… Did I cross-reference data across at least two human-curated sources?


âœ… Did I perform at least one task manually before accepting the AIâ€™s version?


âœ… Did I identify any unstated assumptions in the AIâ€™s output?


âœ… Did I treat GenAI as a thought partnerâ€”not a source of truth?


âœ… Did I deliberately introduce friction into the process (slowing down, comparing, double-checking)?


âœ… Did I stop and ask: What am I trusting without verifying?


âœ… Did we share/cite with the reader of our OSINT product how we used AI? 






This blog has been crossposted on ShadowDragaon.io where i am currently working as the Director of Intelligence & Collection innovation.









Tags:

osint
analysis
AI

OSINT
analysis
AI















 
 
 


Recent PostsSee All




Cryptography & OSINT - Can you read Emoji? ğŸ•µï¸â€â™‚ï¸ğŸ“–â“



 
 
 



Cryptography & OSINT - The fundamentals



 
 
 



Audio OSINT



 
 
 




















  

Email: INFO@DUTCHOSINTGUY.COM 
â€‹ 
Encrypted Email: DUTCHOSINTGUY[@]PROTONMAIL.COM











bottom of page
