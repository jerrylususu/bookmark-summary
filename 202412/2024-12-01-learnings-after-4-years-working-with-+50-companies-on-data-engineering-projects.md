# Learnings after 4 years working with +50 companies on data engineering projects
- URL: https://javisantana.com/2024/11/30/learnings-after-4-years-data-eng.html
- Added At: 2024-12-01 07:20:24
- [Link To Text](2024-12-01-learnings-after-4-years-working-with-+50-companies-on-data-engineering-projects_raw.md)

## TL;DR
作者在Tinybird工作4年，专注于实时数据工程，强调快速处理大量数据的重要性，并指出许多项目存在数据浪费和工具过度依赖的问题。他提出了数据一致性、摄取监控、质量监控等关键点，并强调硬件利用和端到端延迟的权衡。最后，他认为基本工具和硬件能力是数据工程的核心。

## Summary
1. **工作背景**：
   - 作者在Tinybird公司工作4年，帮助超过50家公司进行数据工程项目，从初创公司到世界顶级公司。
   - Tinybird主要解决特定项目，包括构建数据平台和重构现有系统以满足实时需求。

2. **实时数据工程定义**：
   - 实时数据工程不仅仅是使用Kafka、Spark、Flink等工具，而是指在原有基础上实现快速处理。
   - 特点包括大量数据、低延迟、亚秒级查询和合理成本。

3. **实际学习**：
   - **传统ETL误解**：许多人认为快速处理大量数据不可能，但实际上大多数情况可以通过优化设计实现实时处理。
   - **数据浪费**：大多数项目存储了大量从未使用的数据，且每天都在处理这些数据。
   - **工具与原则**：人们过于关注学习工具，而忽视了基本原则，如数据排序可以显著提高查询速度。
   - **数据一致性**：许多项目假设数据总是正确的，但实际上数据重复加载问题普遍存在，需要考虑数据修复。
   - **数据摄取**：数据摄取是工作的80%，但通常未被监控，摄取失败会导致整个管道崩溃。
   - **数据质量**：数据质量监控如同生产环境中的单元测试，需要持续监控。
   - **数据模式**：无论何时，都需要决定数据模式，JSON在某些情况下不错，但不是解决方案，会导致硬件成本增加。
   - **开放模式**：虽然有些项目需要开放模式，但无模式的大规模应用成本高昂，需要区分常见用例和长尾事件。
   - **三选二原则**：快速、廉价、灵活，只能选择其中两个。
   - **硬件利用**：要保持高可用性，硬件大部分时间应处于闲置状态。
   - **端到端延迟**：端到端延迟与硬件成本成反比，需要大量资金才能从10秒降低到低秒级。
   - **操作假设**：人们总是假设操作会顺利完成，使用不可变工作流和原子操作可以避免数据错误。
   - **硬件能力**：大多数人缺乏对当前硬件能力的直觉，简单估算可以帮助理解：单机每秒可处理约500MB数据。
   - **基本工具**：大多数公司只需要基本的bash/make知识、单实例SQL处理引擎、分布式文件系统、git和开发工作流（CI/CD），其他都是附加功能。

4. **个人成长**：
   - 作者从这些项目中学到了很多关于人的方面，但这将是另一个故事。
